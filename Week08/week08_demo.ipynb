{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc6e37f",
   "metadata": {},
   "source": [
    "# Week 08 Live Coding Demo — Statistics & Probability II\n",
    "\n",
    "**Covered today (new examples distinct from slides)**\n",
    "1. Central Limit Theorem (CLT) — means of exponential waiting times\n",
    "2. Confidence intervals: Gaussian mean (σ known), Gaussian mean (σ unknown, t‑based), Poisson rate\n",
    "3. Propagation of uncertainty: kinetic energy K = ½ m v² — linear approx vs Monte Carlo\n",
    "4. Hypothesis tests: z‑test for sensor bias; Poisson rate increase test with z‑equivalent\n",
    "5. Likelihoods & likelihood ratio: Gaussian mean and Poisson rate (new datasets); link to z²\n",
    "6. Correlation & covariance: dual photodiodes and 4‑channel array cross‑talk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136fe10",
   "metadata": {},
   "source": [
    "## 0) Imports, RNG seed, and plotting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core numerical computing and plotting libraries\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "# Mathematical functions for statistical calculations\n",
    "from math import sqrt, pi, exp, factorial\n",
    "# Statistical distributions for hypothesis testing and confidence intervals\n",
    "from scipy.stats import norm, t, chi2, poisson\n",
    "\n",
    "# Set random number generator with fixed seed for reproducible results\n",
    "rng = np.random.default_rng(808)\n",
    "\n",
    "# Configure matplotlib for clean, publication-ready plots\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (6.2, 3.8),  # Standard figure size\n",
    "    \"axes.grid\": True,              # Add grid for easier reading\n",
    "    \"axes.spines.top\": False,       # Remove top spine for cleaner look\n",
    "    \"axes.spines.right\": False,     # Remove right spine for cleaner look\n",
    "    \"font.size\": 11,                # Readable font size\n",
    "})\n",
    "print(\"Environment ready — numpy\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1289d",
   "metadata": {},
   "source": [
    "## 1) Central Limit Theorem (CLT) — means of exponential waiting times\n",
    "\n",
    "**Story**\n",
    "- A detector sees random triggers with waiting time $T\\sim\\mathrm{Exponential}(\\lambda)$ (very non‑Gaussian).\n",
    "- We average **N** independent waiting times to estimate the mean wait $1/\\lambda$.\n",
    "\n",
    "**Goals**\n",
    "- Show that the distribution of the **sample mean** becomes approximately Gaussian as N grows.\n",
    "- Verify the predicted mean and standard deviation $\\mu = 1/\\lambda,\\ \\sigma_{\\bar T}=\\frac{1/\\lambda}{\\sqrt{N}}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbfacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for exponential distribution simulation\n",
    "lam = 0.6  # events per second → true mean wait 1/lam = 1.67 seconds\n",
    "M   = 20000  # number of repeated \"experiments\" per N (large for good statistics)\n",
    "\n",
    "def sample_means(N):\n",
    "    \"\"\"Generate M sample means, each from N exponential waiting times.\n",
    "    \n",
    "    Args:\n",
    "        N: Number of exponential samples to average for each mean\n",
    "        \n",
    "    Returns:\n",
    "        Array of M sample means\n",
    "    \"\"\"\n",
    "    # Generate M experiments, each with N exponential waiting times\n",
    "    # scale=1/lam is the mean of the exponential distribution\n",
    "    waits = rng.exponential(scale=1/lam, size=(M, N))\n",
    "    # Average across the N samples for each experiment (axis=1)\n",
    "    return waits.mean(axis=1)\n",
    "\n",
    "# Create subplot layout for comparing different sample sizes\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,3.6))\n",
    "for j, N in enumerate([2, 5, 20]):\n",
    "    # Generate sample means for this N\n",
    "    means = sample_means(N)\n",
    "    \n",
    "    # Plot histogram of sample means\n",
    "    ax[j].hist(means, bins=60, density=True, alpha=0.7, label=f\"N={N}\")\n",
    "    \n",
    "    # Calculate theoretical CLT parameters\n",
    "    mu  = 1/lam  # True mean of exponential distribution\n",
    "    sig = (1/lam)/np.sqrt(N)  # Standard error of the mean (CLT prediction)\n",
    "    \n",
    "    # Generate points for theoretical Gaussian curve\n",
    "    xs = np.linspace(mu - 4*sig, mu + 4*sig, 400)\n",
    "    # Gaussian PDF: (1/σ√(2π)) * exp(-(x-μ)²/(2σ²))\n",
    "    gauss = (1/(sig*np.sqrt(2*np.pi))) * np.exp(-(xs-mu)**2/(2*sig**2))\n",
    "    \n",
    "    # Overlay theoretical Gaussian approximation\n",
    "    ax[j].plot(xs, gauss, \"k--\", lw=2, label=\"Gaussian approx\")\n",
    "    ax[j].set_title(f\"mean of N={N} exponential waits\")\n",
    "    ax[j].set_xlabel(\"sample mean wait [s]\"); ax[j].set_ylabel(\"density\")\n",
    "    ax[j].legend()\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2449b",
   "metadata": {},
   "source": [
    "## 2) Confidence intervals (CIs)\n",
    "\n",
    "We construct intervals that—across many repeated experiments—cover the true parameter at a chosen rate.\n",
    "We keep **units** and **assumptions** explicit in each example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f7a44",
   "metadata": {},
   "source": [
    "### 2a) CI for a Gaussian mean — instrument σ known (clock frequency)\n",
    "\n",
    "**Story**\n",
    "- A frequency counter measures a stable reference; manufacturer specifies readout noise $\\sigma_{\\text{spec}}$.\n",
    "- We average N readings and quote a 95% CI using the known $\\sigma_{\\text{spec}}$.\n",
    "\n",
    "**Assumptions**\n",
    "- Readout noise is Gaussian with known standard deviation $\\sigma_{\\text{spec}}$.\n",
    "- Samples are independent (reasonable for separated readings).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13bc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters (unknown in real experiments)\n",
    "mu_true   = 10.000_000  # MHz (true reference frequency, unknown in practice)\n",
    "sigma_spec = 0.003      # MHz (instrument specification - known from manufacturer)\n",
    "N = 80                  # number of independent readings\n",
    "\n",
    "# Simulate measurements: true value + Gaussian noise\n",
    "x = mu_true + rng.normal(0, sigma_spec, size=N)\n",
    "\n",
    "# Calculate sample statistics\n",
    "xbar = x.mean()  # Sample mean\n",
    "se   = sigma_spec/np.sqrt(N)  # Standard error of the mean (using known σ)\n",
    "\n",
    "# 95% confidence interval: x̄ ± 1.96 * SE\n",
    "# 1.96 is the 97.5th percentile of standard normal (two-sided 95% CI)\n",
    "L, U = xbar - 1.96*se, xbar + 1.96*se\n",
    "\n",
    "# Visualization\n",
    "xs = np.linspace(mu_true-0.02, mu_true+0.02, 400)\n",
    "plt.axvspan(L, U, color=\"tab:blue\", alpha=0.2, label=\"95% CI\")  # CI region\n",
    "plt.axvline(xbar, color=\"tab:blue\", label=f\"mean = {xbar:.6f} MHz\")  # Sample mean\n",
    "plt.axvline(mu_true, color=\"k\", ls=\"--\", label=\"true (hidden)\")  # True value (for comparison)\n",
    "plt.title(\"Clock frequency — 95% CI with known σ\")\n",
    "plt.xlabel(\"frequency [MHz]\"); plt.legend(); plt.show()\n",
    "\n",
    "print(f\"95% CI: [{L:.6f}, {U:.6f}] MHz  (half-width {1.96*se:.6f} MHz)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15813ee1",
   "metadata": {},
   "source": [
    "### 2b) CI for a Gaussian mean — σ unknown (t‑based, small N)\n",
    "\n",
    "**Story**\n",
    "- We measure laser line center with a spectrometer (small N). Noise σ is not known a priori.\n",
    "- Use the **t distribution** with $N-1$ degrees of freedom to inflate uncertainty for small N.\n",
    "\n",
    "**Assumptions**\n",
    "- Measurement errors are approximately Gaussian.\n",
    "- Samples are independent; σ is estimated by the sample standard deviation $s$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c58bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 9  # Small sample size (typical for expensive measurements)\n",
    "true_wavelength = 632.8  # nm (HeNe laser line, hidden truth)\n",
    "# Simulate measurements with unknown standard deviation\n",
    "reads = true_wavelength + rng.normal(0, 0.06, size=N)  # unknown σ≈0.06 nm\n",
    "\n",
    "# Calculate sample statistics\n",
    "xbar = reads.mean()  # Sample mean\n",
    "s = reads.std(ddof=1)  # Sample standard deviation (ddof=1 for unbiased estimate)\n",
    "\n",
    "# t-distribution critical value for 95% two-sided confidence interval\n",
    "# df = N-1 degrees of freedom, 0.975 = 97.5th percentile (two-sided 95%)\n",
    "tcrit = t.ppf(0.975, df=N-1)\n",
    "\n",
    "# t-based confidence interval: x̄ ± t_crit * s/√N\n",
    "L, U = xbar - tcrit*s/np.sqrt(N), xbar + tcrit*s/np.sqrt(N)\n",
    "\n",
    "# Visualization with error bars\n",
    "plt.errorbar([0], [xbar], yerr=tcrit*s/np.sqrt(N), fmt=\"o\", capsize=6, label=\"95% CI\")\n",
    "plt.axhline(true_wavelength, color=\"k\", ls=\"--\", label=\"true (hidden)\")\n",
    "plt.xticks([]); plt.ylabel(\"wavelength [nm]\"); plt.title(\"t‑interval for mean (σ unknown)\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "print(f\"mean={xbar:.3f} nm, s={s:.3f} nm, 95% CI: [{L:.3f}, {U:.3f}] nm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7c13f",
   "metadata": {},
   "source": [
    "## 3) Propagation of uncertainty — kinetic energy $K=\\tfrac{1}{2}mv^2$\n",
    "\n",
    "**Story**\n",
    "- We measure mass $m$ and velocity $v$ (with uncertainties) and report kinetic energy $K$.\n",
    "- How does measurement uncertainty in $m,v$ propagate to $K$?\n",
    "\n",
    "**Plan**\n",
    "1. Linear (first‑order) propagation: $\\sigma_K^2 \\approx (\\tfrac{\\partial K}{\\partial m})^2\\sigma_m^2 + (\\tfrac{\\partial K}{\\partial v})^2\\sigma_v^2$ (assuming independence).\n",
    "2. Monte Carlo: sample $m,v$ from their uncertainties, compute $K$, and compare the histogram to the linear‑Gaussian approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True values and measurement uncertainties\n",
    "m_true, sigma_m = 0.250, 0.002   # kg (mass ± uncertainty)\n",
    "v_true, sigma_v = 12.0,  0.25    # m/s (velocity ± uncertainty)\n",
    "\n",
    "# Calculate true kinetic energy K = ½mv²\n",
    "K = 0.5*m_true*v_true**2\n",
    "\n",
    "# Linear uncertainty propagation: σ_K² = (∂K/∂m)²σ_m² + (∂K/∂v)²σ_v²\n",
    "# Partial derivatives of K = ½mv² with respect to m and v\n",
    "dK_dm = 0.5 * v_true**2  # ∂K/∂m = ½v²\n",
    "dK_dv = m_true * v_true  # ∂K/∂v = mv\n",
    "# Linear approximation of uncertainty (assumes independent, Gaussian errors)\n",
    "sigma_K_lin = np.sqrt((dK_dm*sigma_m)**2 + (dK_dv*sigma_v)**2)\n",
    "\n",
    "# Monte Carlo simulation: sample from measurement uncertainties\n",
    "N = 200000  # Large number of samples for good statistics\n",
    "m = rng.normal(m_true, sigma_m, size=N)  # Sample masses from N(m_true, σ_m)\n",
    "v = rng.normal(v_true, sigma_v, size=N)  # Sample velocities from N(v_true, σ_v)\n",
    "K_samples = 0.5*m*v**2  # Calculate K for each (m,v) pair\n",
    "K_bar, K_std = K_samples.mean(), K_samples.std(ddof=1)  # MC statistics\n",
    "\n",
    "# Visualization: compare MC distribution with linear Gaussian approximation\n",
    "plt.hist(K_samples, bins=120, density=True, alpha=0.6, label=\"MC samples\")\n",
    "# Theoretical Gaussian from linear propagation\n",
    "xs = np.linspace(K - 5*sigma_K_lin, K + 5*sigma_K_lin, 400)\n",
    "gauss = (1/(sigma_K_lin*np.sqrt(2*np.pi))) * np.exp(-(xs-K)**2/(2*sigma_K_lin**2))\n",
    "plt.plot(xs, gauss, \"k--\", lw=2, label=\"linear Gaussian approx\")\n",
    "plt.xlabel(\"kinetic energy K [J]\"); plt.ylabel(\"PDF\")\n",
    "plt.title(\"Uncertainty propagation to K = ½ m v²\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "print(f\"Linear approx: K≈{K:.3f} J, σ_K≈{sigma_K_lin:.3f} J\")\n",
    "print(f\"Monte Carlo  : mean≈{K_bar:.3f} J, std≈{K_std:.3f} J\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c11bb8",
   "metadata": {},
   "source": [
    "## 4) Hypothesis testing\n",
    "\n",
    "We demonstrate two common tests:\n",
    "- **z‑test (Gaussian, known σ)**: Is a magnetometer biased vs a zero‑field reference?\n",
    "- **Poisson counting test**: Did the event rate increase above a known background?\n",
    "\n",
    "We report both p‑values and an equivalent **z‑sigma** (one‑sided) for intuition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ac538",
   "metadata": {},
   "source": [
    "### 4a) z‑test — magnetometer bias check (known σ)\n",
    "\n",
    "**Story**\n",
    "- Magnetometer readings near a mu‑metal shield should be zero on average (μ₀=0).\n",
    "- Manufacturer reports readout $\\sigma_{\\text{spec}}$; we average N readings and test for bias.\n",
    "\n",
    "**Test**\n",
    "- $z = \\dfrac{\\bar{x} - \\mu_0}{\\sigma_{\\text{spec}}/\\sqrt{N}}$, p‑value (two‑sided) = $2\\,\\Phi(-|z|)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c04673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters: H0: μ = μ0 (no bias) vs H1: μ ≠ μ0 (bias present)\n",
    "mu0, sigma_spec, N = 0.0, 0.12, 120  # Null hypothesis, known σ, sample size\n",
    "\n",
    "# Simulate data with small bias (0.03) plus random noise\n",
    "x = mu0 + 0.01 + rng.normal(0, sigma_spec, size=N)\n",
    "\n",
    "# Calculate test statistic\n",
    "xbar = x.mean()  # Sample mean\n",
    "# z-statistic: (x̄ - μ₀) / (σ/√N) ~ N(0,1) under H0\n",
    "z = (xbar - mu0)/(sigma_spec/np.sqrt(N))\n",
    "# Two-sided p-value: P(|Z| ≥ |z|) = 2 * P(Z ≥ |z|)\n",
    "p_two = 2*norm.sf(abs(z)) # sf: \"survival function\" = 1 - CDF(x)\n",
    "\n",
    "# Visualization of standard normal distribution and test result\n",
    "xs = np.linspace(-4, 4, 400)\n",
    "plt.plot(xs, norm.pdf(xs), label=\"N(0,1)\")  # Standard normal PDF\n",
    "plt.axvline(z, color=\"r\", lw=2, label=f\"observed z = {z:.2f}, p={p_two:.3f}\")\n",
    "plt.title(\"z‑test for bias (two‑sided)\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "print(f\"mean={xbar:.3f}, z={z:.2f}, two‑sided p={p_two:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0c223",
   "metadata": {},
   "source": [
    "### 4b) Poisson counting test — rate increase?\n",
    "\n",
    "**Story**\n",
    "- A background monitor historically averages $b=10$ counts/min.\n",
    "- Today we observe $n=19$ counts in 1 minute. Is this a significant increase?\n",
    "\n",
    "**Test**\n",
    "- One‑sided p‑value $p=\\mathbb{P}(N\\ge n\\,|\\,\\lambda=b)$ under $\\mathrm{Poisson}(b)$.\n",
    "- Convert to a one‑sided z‑sigma: $z = \\Phi^{-1}(1-p)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc16cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters: H0: λ = b (background rate) vs H1: λ > b (rate increase)\n",
    "b, n = 10.0, 19  # Background rate b=10 counts/min, observed n=19 counts\n",
    "\n",
    "# One-sided p-value: P(N ≥ n | λ = b) under Poisson(b)\n",
    "# poisson.sf(n-1, b) = P(N ≥ n) = 1 - P(N ≤ n-1)\n",
    "p = poisson.sf(n-1, b)\n",
    "# Convert p-value to equivalent z-score for intuitive interpretation\n",
    "z_equiv = norm.isf(p)  # Inverse survival function: Φ⁻¹(1-p)\n",
    "\n",
    "print(f\"one‑minute counts: observed n={n}, expected b={b}\")\n",
    "print(f\"p = {p:.3f}, one‑sided z ≈ {z_equiv:.2f}σ\")\n",
    "\n",
    "# Visualization of Poisson distribution and test result\n",
    "k = np.arange(0, 35)  # Range of possible counts\n",
    "pmf = poisson.pmf(k, b)  # Probability mass function under H0\n",
    "plt.bar(k, pmf, alpha=0.6, label=\"H0: Poisson(b=10)\")  # Full distribution\n",
    "plt.bar(k[k>=n], pmf[k>=n], color=\"crimson\", label=f\"tail p={p:.3f}\")  # Tail region\n",
    "plt.axvline(n, color=\"crimson\", lw=2, label=f\"n={n}\")  # Observed value\n",
    "plt.xlabel(\"counts in 1 min\"); plt.ylabel(\"PMF\")\n",
    "plt.title(\"Poisson test for rate increase\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659189af",
   "metadata": {},
   "source": [
    "## 5) Likelihoods and likelihood‑ratio tests (LRT)\n",
    "\n",
    "We visualize likelihood functions and connect the **z‑test** to an LRT in the Gaussian‑mean case.\n",
    "New datasets are used to avoid overlap with slides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db14c2",
   "metadata": {},
   "source": [
    "### 5a) Gaussian mean (σ known): likelihood curve and LRT equals z²\n",
    "\n",
    "**Story**\n",
    "- A Hall probe measures field strength repeatedly; σ is known from calibration.\n",
    "- We plot the likelihood $L(\\mu)$ vs μ, find the MLE, and compute the LRT statistic $S=-2\\log\\Lambda$.\n",
    "- In this simple case, $S=z^2$ (numerically equal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Gaussian likelihood demonstration\n",
    "sigma, mu0, N = 0.25, 1.2, 70  # Known σ, null hypothesis μ₀, sample size\n",
    "# Generate data with small shift from null hypothesis\n",
    "x = mu0 + 0.07 + rng.normal(0, sigma, size=N)\n",
    "muhat = x.mean()  # Maximum likelihood estimate\n",
    "\n",
    "def logL(mu): \n",
    "    \"\"\"Log-likelihood function for Gaussian mean with known σ.\n",
    "    \n",
    "    For N independent observations x_i ~ N(μ, σ²) stored in x (nonlocal variable):\n",
    "    log L(μ) = -½∑(x_i - μ)²/σ² + constant\n",
    "    \"\"\"\n",
    "    return -0.5*np.sum((x-mu)**2)/sigma**2\n",
    "\n",
    "# Evaluate likelihood over a range of μ values\n",
    "mus = np.linspace(muhat-1.5*sigma, muhat+1.5*sigma, 400)\n",
    "logL_vals = np.array([logL(m) for m in mus])\n",
    "# Normalize to relative likelihood: L(μ)/L(μ̂) = exp(logL(μ) - logL(μ̂))\n",
    "logL_vals -= logL_vals.max()\n",
    "\n",
    "# Likelihood ratio test statistic: S = -2 log Λ = -2(logL(μ₀) - logL(μ̂))\n",
    "S = -2*(logL(mu0) - logL(muhat))\n",
    "# For Gaussian case, S should equal z² where z is the z-test statistic\n",
    "z = (muhat - mu0)/(sigma/np.sqrt(N))\n",
    "\n",
    "# Visualization of likelihood function\n",
    "plt.plot(mus, np.exp(logL_vals), label=\"relative likelihood\")\n",
    "plt.axvline(muhat, color=\"crimson\", lw=2, label=f\"MLE μ̂={muhat:.3f}\")\n",
    "plt.axvline(mu0, color=\"k\", ls='--', label=f'$\\mu_0$={mu0} (hidden)')\n",
    "plt.xlabel(\"μ\"); plt.ylabel(\"L(μ)/L(μ̂)\"); plt.title(\"Gaussian likelihood vs μ\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "print(f\"LRT S = {S:.3f}, z² = {z**2:.3f}  (should match for this case)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57788bc4",
   "metadata": {},
   "source": [
    "### 5b) Poisson rate likelihood — skewed shape at low counts\n",
    "\n",
    "**Story**\n",
    "- In a short run, only a few decays are observed. Likelihood for the rate λ is asymmetric.\n",
    "\n",
    "**Goal**\n",
    "- Plot the relative likelihood $L(\\lambda)/L(\\hat\\lambda)$ and mark the MLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Poisson counting experiment: n counts observed in time T\n",
    "n, T = 5, 30.0  # 5 counts in 30 seconds\n",
    "lam_true = 0.12  # True rate (hidden in real experiments)\n",
    "\n",
    "# Evaluate likelihood over a range of rate values λ\n",
    "lam = np.linspace(0.01, 0.6, 400)\n",
    "# Log-likelihood for Poisson: log L(λ) = n log(λT) - λT - log(n!)\n",
    "# where n ~ Poisson(λT) and λT is the expected number of counts\n",
    "logL = n*np.log(lam*T) - lam*T - np.log(math.factorial(n))\n",
    "# Normalize to relative likelihood: L(λ)/L(λ̂)\n",
    "logL -= logL.max()\n",
    "\n",
    "# Maximum likelihood estimate: λ̂ = n/T\n",
    "lam_hat = n/T\n",
    "\n",
    "# Visualization of Poisson likelihood function\n",
    "plt.plot(lam, np.exp(logL), label=\"relative likelihood\")\n",
    "plt.axvline(lam_hat, color=\"crimson\", lw=2, label=f\"MLE λ̂={lam_hat:.3f} s⁻¹\")\n",
    "plt.axvline(lam_true, color=\"k\", ls=\"--\", label=f\"true λ (hidden)\")\n",
    "plt.xlabel(\"λ [s⁻¹]\"); plt.ylabel(\"L(λ)/L(λ̂)\")\n",
    "plt.title(\"Poisson likelihood for a rate\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1dc7bc",
   "metadata": {},
   "source": [
    "## 6) Correlation and covariance\n",
    "\n",
    "Two quick physics‑motivated demos:\n",
    "1. **Dual photodiodes** measuring the same fluctuating light intensity (gain + noise) → correlation and a linear trend.\n",
    "2. **4‑channel sensor array** with cross‑talk → covariance matrix heatmap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bebcd",
   "metadata": {},
   "source": [
    "### 6a) Correlation — dual photodiodes tracking the same source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 400  # Number of simultaneous measurements\n",
    "\n",
    "# Simulate correlated photodiode measurements\n",
    "# Common light intensity I (log-normal distribution for realistic intensity variations)\n",
    "I = rng.lognormal(mean=0.0, sigma=0.3, size=N)\n",
    "# Photodiode A: linear response to light + independent noise\n",
    "A = 1.8*I + rng.normal(0, 0.2, size=N)\n",
    "# Photodiode B: different gain and offset + independent noise\n",
    "B = 1.5*I + 0.3 + rng.normal(0, 0.25, size=N)\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "r = np.corrcoef(A, B)[0,1]  # Extract correlation from 2x2 correlation matrix\n",
    "\n",
    "# Linear regression: B = slope*A + intercept\n",
    "# Set up design matrix [A, 1] for least squares -- Will cover later \n",
    "A1 = np.column_stack([A, np.ones_like(A)])\n",
    "slope, intercept = np.linalg.lstsq(A1, B, rcond=None)[0]\n",
    "\n",
    "# Visualization of correlation and linear relationship\n",
    "plt.scatter(A, B, s=16, alpha=0.7, label=f\"data (r≈{r:.2f})\")\n",
    "xs = np.linspace(A.min(), A.max(), 100)\n",
    "plt.plot(xs, slope*xs + intercept, \"crimson\", lw=2, label=f\"fit B≈{slope:.2f}·A+{intercept:.2f}\")\n",
    "plt.xlabel(\"Photodiode A [a.u.]\"); plt.ylabel(\"Photodiode B [a.u.]\")\n",
    "plt.title(\"Two sensors viewing the same light source\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f661cf",
   "metadata": {},
   "source": [
    "### 6b) Covariance matrix — 4‑channel array with cross‑talk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000  # Number of measurements per channel\n",
    "\n",
    "# Simulate 4-channel sensor array with cross-talk\n",
    "# Two common signal sources (s1, s2) that affect multiple channels\n",
    "s1 = rng.normal(size=N)  # Primary signal source\n",
    "s2 = 0.5*rng.normal(size=N)  # Secondary signal source (weaker)\n",
    "\n",
    "# Each channel has different sensitivity to common signals + independent noise\n",
    "# Channel 1: strong response to s1, weak to s2\n",
    "X1 = 1.0*s1 + 0.3*s2 + rng.normal(scale=0.4, size=N)\n",
    "# Channel 2: moderate response to s1, negative to s2 (phase difference)\n",
    "X2 = 0.6*s1 - 0.2*s2 + rng.normal(scale=0.5, size=N)\n",
    "# Channel 3: weak negative to s1, strong to s2\n",
    "X3 = -0.3*s1 + 0.9*s2 + rng.normal(scale=0.6, size=N)\n",
    "# Channel 4: moderate response to both signals\n",
    "X4 = 0.4*s1 + 0.4*s2 + rng.normal(scale=0.3, size=N)\n",
    "\n",
    "# Stack channels into 4×N data matrix\n",
    "X = np.vstack([X1,X2,X3,X4])\n",
    "# Calculate 4×4 covariance matrix: C[i,j] = Cov(X_i, X_j)\n",
    "C = np.cov(X)\n",
    "\n",
    "# Visualization of covariance matrix as heatmap\n",
    "plt.imshow(C, cmap=\"coolwarm\")  # Red = positive, blue = negative correlation\n",
    "plt.colorbar(label=\"covariance\")\n",
    "plt.xticks([0,1,2,3], [\"ch1\",\"ch2\",\"ch3\",\"ch4\"])\n",
    "plt.yticks([0,1,2,3], [\"ch1\",\"ch2\",\"ch3\",\"ch4\"])\n",
    "plt.title(\"Covariance matrix — 4‑channel array\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
