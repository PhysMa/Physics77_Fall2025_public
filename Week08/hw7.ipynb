{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e51c6b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw7.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "#below line allows matplotlib plots to appear in cell output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbac647",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 1**: Central Limit Theorem Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba21f7f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part a: Uniform Distribution Sampling\n",
    "\n",
    "Write a function `sample_uniform_mean(a, b, n_samples)` that samples from a uniform distribution and returns the mean of the samples.\n",
    "\n",
    "[numpy uniform dist. docs](https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html)\n",
    "\n",
    "**Requirements:**\n",
    "- Use `np.random` methods to generate samples\n",
    "- Return the mean of the samples\n",
    "\n",
    "**Parameters:**\n",
    "- `a`: float, lower bound of uniform distribution\n",
    "- `b`: float, upper bound of uniform distribution  \n",
    "- `n_samples`: int, number of samples to draw\n",
    "\n",
    "**Returns:**\n",
    "- `sample_mean`: float, mean of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca35b71",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def sample_uniform_mean(a, b, n_samples):\n",
    "    # Write your code here!\n",
    "    \n",
    "    return sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6341c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b805b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part b: Gamma Distribution Sampling\n",
    "\n",
    "Write a function `sample_gamma_mean(shape, scale, n_samples)` that samples from a gamma distribution and returns the mean of the samples.\n",
    "\n",
    "[numpy gamma dist. docs](https://numpy.org/doc/stable/reference/random/generated/numpy.random.gamma.html)\n",
    "\n",
    "**Requirements:**\n",
    "- Use `np.random` to generate samples\n",
    "- Return the mean of the samples\n",
    "\n",
    "**Parameters:**\n",
    "- `shape`: float, shape parameter of gamma distribution\n",
    "- `scale`: float, scale parameter of gamma distribution\n",
    "- `n_samples`: int, number of samples to draw\n",
    "\n",
    "**Returns:**\n",
    "- `sample_mean`: float, mean of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb967f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def sample_gamma_mean(shape, scale, n_samples):\n",
    "    # Write your code here!\n",
    "    return sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9bafe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad6107",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part c: Central Limit Theorem Visualization\n",
    "\n",
    "Write a function `plot_sample_means(use_uniform, N, n_samples=100, bins=30, show_plot=False)` that demonstrates the Central Limit Theorem by plotting a histogram of sample means.\n",
    "\n",
    "**Requirements:**\n",
    "- If `use_uniform=True`, use `sample_uniform_mean(0, 10, n_samples)` for each trial\n",
    "- If `use_uniform=False`, use `sample_gamma_mean(2, 2, n_samples)` for each trial\n",
    "- Perform N trials to collect N sample means\n",
    "- Create a histogram of the sample means with specified number of bins\n",
    "- Set x-axis label to \"Sample Mean\"\n",
    "- Set y-axis label to \"Density\"  \n",
    "- Set title to include \"Central Limit Theorem\" and distribution information\n",
    "- Add a grid to the plot\n",
    "- The function should return the matplotlib figure object\n",
    "\n",
    "**Parameters:**\n",
    "- `use_uniform`: bool, if True use uniform distribution, else use gamma\n",
    "- `N`: int, number of trials (number of sample means to collect)\n",
    "- `n_samples`: int, default 100, number of samples per trial\n",
    "- `bins`: int, default 30, number of histogram bins\n",
    "- `show_plot`: bool, default False. If True, call `plt.show()`\n",
    "\n",
    "**Returns:**\n",
    "- `fig`: matplotlib figure object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce283684",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_sample_means(use_uniform, N, n_samples=100, bins=30, show_plot=False):\n",
    "    #compute an array of sample means\n",
    "    \n",
    "    ...\n",
    "\n",
    "    # Create histogram plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "    ...\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705b255",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test the function and demonstrate CLT convergence with different N values\n",
    "np.random.seed(rng_seed)  # Set seed for reproducible results\n",
    "\n",
    "# Test individual functions first\n",
    "print(\"Testing individual functions:\")\n",
    "uniform_mean = sample_uniform_mean(0, 10, 1000)\n",
    "gamma_mean = sample_gamma_mean(2, 2, 1000)\n",
    "print(f\"Sample mean from Uniform(0,10): {uniform_mean:.3f} (theoretical: 5.0)\")\n",
    "print(f\"Sample mean from Gamma(2,2): {gamma_mean:.3f} (theoretical: 4.0)\")\n",
    "\n",
    "# Demonstrate CLT convergence with different N values\n",
    "print(\"\\nDemonstrating Central Limit Theorem convergence:\")\n",
    "\n",
    "# Small N - should show some deviation from normal\n",
    "fig1 = plot_sample_means(use_uniform=True, N=50, n_samples=100, show_plot=True)\n",
    "print(\"Uniform distribution with N=50 trials\")\n",
    "\n",
    "# Medium N - better convergence\n",
    "fig2 = plot_sample_means(use_uniform=True, N=200, n_samples=100, show_plot=True) \n",
    "print(\"Uniform distribution with N=200 trials\")\n",
    "\n",
    "# Large N - clear normal distribution\n",
    "fig3 = plot_sample_means(use_uniform=True, N=1000, n_samples=100, show_plot=True)\n",
    "print(\"Uniform distribution with N=1000 trials\")\n",
    "\n",
    "# Compare gamma distribution\n",
    "fig4 = plot_sample_means(use_uniform=False, N=500, n_samples=100, show_plot=True)\n",
    "print(\"Gamma distribution with N=500 trials\")\n",
    "\n",
    "# Show effect of sample size per trial\n",
    "fig5 = plot_sample_means(use_uniform=True, N=500, n_samples=25, show_plot=True)\n",
    "print(\"Uniform distribution with N=500 trials, n_samples=25 (wider distribution)\")\n",
    "\n",
    "fig6 = plot_sample_means(use_uniform=True, N=500, n_samples=400, show_plot=True)\n",
    "print(\"Uniform distribution with N=500 trials, n_samples=400 (narrower distribution)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad98980",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7268bb",
   "metadata": {},
   "source": [
    "## **Question 2**: Error Propagation\n",
    "\n",
    "When we have a function $y = g(x_1, x_2, \\ldots, x_n)$ where each parameter $x_i$ has an associated uncertainty $\\sigma_i$, the propagated uncertainty in $y$ is given by:\n",
    "\n",
    "$$\\sigma_y = \\sqrt{\\sum_{i=1}^{n} \\left(\\frac{\\partial g}{\\partial x_i}\\right)^2 \\sigma_i^2}$$\n",
    "\n",
    "This formula assumes that the uncertainties in the input parameters are uncorrelated (independent). Each partial derivative $\\frac{\\partial g}{\\partial x_i}$ is evaluated at the measured values of all parameters.\n",
    "\n",
    "In this question, you will implement error propagation for two different physics formulas by:\n",
    "1. Computing the partial derivatives analytically\n",
    "2. Implementing functions that return both the calculated value and its propagated uncertainty as a tuple `(y, sigma_y)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469ff13",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part a: Projectile Motion Range\n",
    "\n",
    "The range of a projectile launched at angle $\\theta$ with initial velocity $v_0$ is given by:\n",
    "\n",
    "$$R = \\frac{v_0^2 \\sin(2\\theta)}{g}$$\n",
    "\n",
    "where $g = 9.81$ m/s² is the acceleration due to gravity.\n",
    "\n",
    "Write a function `projectile_range_with_error(v0, sigma_v0, theta, sigma_theta, g=9.81)` that calculates both the range and its propagated uncertainty.\n",
    "\n",
    "**Requirements:**\n",
    "- Use the error propagation formula with partial derivatives\n",
    "- `theta` should be in radians\n",
    "- Return a tuple `(R, sigma_R)` where `R` is the range and `sigma_R` is the propagated uncertainty\n",
    "\n",
    "**Hint:** You'll need to compute:\n",
    "$\\frac{\\partial R}{\\partial v_0}$, $\\frac{\\partial R}{\\partial \\theta}$\n",
    "and then implement the analytic expression you derive into your code\n",
    "\n",
    "**Parameters:**\n",
    "- `v0`: float, initial velocity in m/s\n",
    "- `sigma_v0`: float, uncertainty in initial velocity  \n",
    "- `theta`: float, launch angle in radians\n",
    "- `sigma_theta`: float, uncertainty in launch angle in radians\n",
    "- `g`: float, default 9.81, acceleration due to gravity in m/s²\n",
    "\n",
    "**Returns:**\n",
    "- `(R, sigma_R)`: tuple of floats, range and its uncertainty in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0246b7",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def projectile_range_with_error(v0, sigma_v0, theta, sigma_theta, g=9.81):\n",
    "    # Calculate the range R\n",
    "    R = ...\n",
    "    \n",
    "    # Calculate partial derivatives\n",
    "    dR_dv0 = ...\n",
    "    dR_dtheta = ...\n",
    "    \n",
    "    # Apply error propagation formula\n",
    "    sigma_R = ...\n",
    "    \n",
    "    return (R, sigma_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70ba05",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3eb067",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part b: Physical Pendulum Period\n",
    "\n",
    "The period of a physical pendulum (a rigid body oscillating about a pivot point) is given by:\n",
    "\n",
    "$$T = 2\\pi \\sqrt{\\frac{I}{mgd}}$$\n",
    "\n",
    "where:\n",
    "- $I$ is the moment of inertia about the pivot point\n",
    "- $m$ is the mass of the pendulum\n",
    "- $g$ is the acceleration due to gravity  \n",
    "- $d$ is the distance from the pivot to the center of mass\n",
    "\n",
    "Write a function `pendulum_period_with_error(I, sigma_I, m, sigma_m, d, sigma_d, g=9.81)` that calculates both the period and its propagated uncertainty.\n",
    "\n",
    "**Requirements:**\n",
    "- Use the error propagation formula with partial derivatives\n",
    "- Return a tuple `(T, sigma_T)` where `T` is the period and `sigma_T` is the propagated uncertainty\n",
    "\n",
    "**Hint:** You'll need to compute:\n",
    "$\\frac{\\partial T}{\\partial I}$, $\\frac{\\partial T}{\\partial m}$, $\\frac{\\partial T}{\\partial d}$\n",
    "\n",
    "**Parameters:**\n",
    "- `I`: float, moment of inertia in kg⋅m²\n",
    "- `sigma_I`: float, uncertainty in moment of inertia\n",
    "- `m`: float, mass in kg\n",
    "- `sigma_m`: float, uncertainty in mass\n",
    "- `d`: float, distance to center of mass in meters\n",
    "- `sigma_d`: float, uncertainty in distance\n",
    "- `g`: float, default 9.81, acceleration due to gravity in m/s²\n",
    "\n",
    "**Returns:**\n",
    "- `(T, sigma_T)`: tuple of floats, period and its uncertainty in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbc241",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def pendulum_period_with_error(I, sigma_I, m, sigma_m, d, sigma_d, g=9.81):\n",
    "    # Calculate the period T\n",
    "    T = ...\n",
    "    \n",
    "    # Calculate partial derivatives\n",
    "    dT_dI = ...\n",
    "    dT_dm = ...\n",
    "    dT_dd = ...\n",
    "    \n",
    "    # Apply error propagation formula\n",
    "    sigma_T = ...\n",
    "    \n",
    "    return (T, sigma_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfa3e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7acf02",
   "metadata": {},
   "source": [
    "## **Question 3**: Covariance and Correlation Analysis\n",
    "\n",
    "Covariance and correlation are fundamental measures of how two variables change together. For a dataset with multiple variables, we can compute:\n",
    "\n",
    "**Covariance Matrix**: $\\text{Cov}(X_i, X_j) = \\frac{1}{n-1} \\sum_{k=1}^{n} (X_{i,k} - \\bar{X_i})(X_{j,k} - \\bar{X_j})$\n",
    "\n",
    "**Correlation Matrix**: $\\text{Corr}(X_i, X_j) = \\frac{\\text{Cov}(X_i, X_j)}{\\sigma_{X_i} \\sigma_{X_j}}$\n",
    "\n",
    "Where correlation values range from -1 (perfect negative correlation) to +1 (perfect positive correlation), with 0 indicating no linear correlation.\n",
    "\n",
    "In this question, you will analyze a physics dataset containing 7 variables that represent related physical quantities. Some variables should show strong correlations based on physical laws, while others should be relatively independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800de95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part a: Computing Covariance and Correlation Matrices\n",
    "\n",
    "Write a function `analyze_covariance(filename)` that reads a CSV data file and computes both the covariance and correlation matrices.\n",
    "\n",
    "**Requirements:**\n",
    "- Read the CSV file using pandas (`pd.read_csv`)\n",
    "- Compute the covariance matrix using numpy (sample covariance with n-1 denominator) (you can also do this by hand, but numpy is much easier/faster)\n",
    "- Compute the correlation matrix using numpy\n",
    "- Return both matrices as numpy arrays\n",
    "\n",
    "**Parameters:**\n",
    "- `filename`: str, csv filename (`physics_data.csv`)\n",
    "\n",
    "**Returns:**\n",
    "- `(cov_matrix, corr_matrix)`: tuple of numpy arrays\n",
    "  - `cov_matrix`: covariance matrix (7x7)\n",
    "  - `corr_matrix`: correlation matrix (7x7)\n",
    "\n",
    "**Note:** The correlation matrix should have 1.0 on the diagonal and values between -1 and 1 elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fcfd9d",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def analyze_covariance(filename):\n",
    "    # Read the CSV file\n",
    "    data = ...\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    data_array = ...\n",
    "    \n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = ...\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = ...\n",
    "    \n",
    "    return cov_matrix, corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1794c95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594c60",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part b: Visualizing Covariance and Correlation Matrices\n",
    "\n",
    "Write a function `plot_covariance_matrices(filename, show_plot=False)` that creates heatmap visualizations of both the covariance and correlation matrices.\n",
    "\n",
    "**Requirements:**\n",
    "- Read the data and compute matrices using your `analyze_covariance` function\n",
    "- Create a figure with two subplots (side by side)\n",
    "- Left subplot: covariance matrix heatmap\n",
    "- Right subplot: correlation matrix heatmap (colorbar range should be `[-1,1]`)\n",
    "- Use appropriate colormaps and include colorbars\n",
    "- Set titles and axis labels with variable names\n",
    "- Return the matplotlib figure object\n",
    "\n",
    "**Parameters:**\n",
    "- `filename`: str, path to the CSV file containing the data\n",
    "- `show_plot`: bool, default False. If True, call `plt.show()`\n",
    "\n",
    "**Returns:**\n",
    "- `fig`: matplotlib figure object containing both heatmaps\n",
    "\n",
    "**Note:** For better visualization, consider using different colormaps for covariance vs correlation matrices.\n",
    "\n",
    "Think about what the correlation matrix says about these data, there's no deliverable on this, but what insight can be gained by examining such a plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38029a66",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_covariance_matrices(filename, show_plot=False):\n",
    "    # Get matrices from part a\n",
    "    ...\n",
    "    \n",
    "    # Read data to get variable names\n",
    "    data = pd.read_csv(filename)\n",
    "    variable_names = ...\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Create covariance heatmap\n",
    "    im1 = ax1.imshow(...)\n",
    "    ax1.set_title('Covariance Matrix')\n",
    "    # ... add labels and colorbar\n",
    "    \n",
    "    # Create correlation heatmap  \n",
    "    im2 = ax2.imshow(...)\n",
    "    ax2.set_title('Correlation Matrix')\n",
    "    # ... add labels and colorbar\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a572b6",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#showing the plot\n",
    "plot_covariance_matrices(\"physics_data.csv\", show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1629184",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312562f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 4**: Poisson Likelihood Estimation\n",
    "\n",
    "The Poisson distribution is fundamental in physics for describing the probability of observing a discrete number of events (like photon counts, radioactive decays, or particle detections) in a fixed interval when events occur independently at a constant average rate.\n",
    "\n",
    "The **Poisson probability mass function** for observing exactly $k$ events when the expected number is $\\lambda$ is:\n",
    "\n",
    "$$P(k|\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$\n",
    "\n",
    "When we have a dataset of $n$ independent observations $\\{k_1, k_2, ..., k_n\\}$, the **likelihood function** represents how probable it is to observe this specific dataset given a particular value of $\\lambda$:\n",
    "\n",
    "$$L(\\lambda) = \\prod_{i=1}^{n} P(k_i|\\lambda) = \\prod_{i=1}^{n} \\frac{\\lambda^{k_i} e^{-\\lambda}}{k_i!}$$\n",
    "\n",
    "For computational convenience, we often work with the **log-likelihood**:\n",
    "\n",
    "$$\\ln L(\\lambda) = \\sum_{i=1}^{n} \\ln P(k_i|\\lambda) = \\sum_{i=1}^{n} \\left[ k_i \\ln(\\lambda) - \\lambda - \\ln(k_i!) \\right]$$\n",
    "\n",
    "The **maximum likelihood estimate (MLE)** is the value of $\\lambda$ that maximizes the likelihood function. For the Poisson distribution, the MLE has the analytical solution: $\\hat{\\lambda} = \\bar{k} = \\frac{1}{n}\\sum_{i=1}^{n} k_i$ (the sample mean).\n",
    "\n",
    "### Part a: Computing the Poisson Likelihood\n",
    "\n",
    "Write a function `poisson_likelihood(data, lambda_val)` that computes the likelihood of observing the given data for a specific value of λ.\n",
    "\n",
    "**Mathematical Steps:**\n",
    "1. For each data point $k_i$, compute $P(k_i|\\lambda) = \\frac{\\lambda^{k_i} e^{-\\lambda}}{k_i!}$\n",
    "2. Multiply all individual probabilities: $L(\\lambda) = \\prod_{i=1}^{n} P(k_i|\\lambda)$\n",
    "\n",
    "**Requirements:**\n",
    "- Use the Poisson probability mass function to compute individual probabilities\n",
    "- Return the product of all probabilities (the likelihood)\n",
    "- Handle potential numerical underflow by using appropriate functions\n",
    "- You may use `scipy.stats.poisson.pmf()` or implement the formula directly\n",
    "\n",
    "**Parameters:**\n",
    "- `data`: array-like, observed count data (integers)\n",
    "- `lambda_val`: float, the Poisson parameter λ\n",
    "\n",
    "**Returns:**\n",
    "- `likelihood`: float, the likelihood L(λ) of observing the data given λ\n",
    "\n",
    "**Hint:** For large datasets, likelihoods can become extremely small. Consider using `np.prod()` or working with log-likelihood and then exponentiating if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28625cbb",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def poisson_likelihood(data, lambda_val):\n",
    "    from scipy.stats import poisson\n",
    "    \n",
    "    # Convert data to numpy array\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Compute individual probabilities\n",
    "    probabilities = ...\n",
    "    \n",
    "    # Compute likelihood as product of probabilities\n",
    "    likelihood = ...\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b62af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47409dc4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part b: Likelihood Curve and Maximum Likelihood Estimation\n",
    "\n",
    "Write a function `plot_likelihood_curve(data, lambda_range=None, n_points=100, show_plot=False)` that plots the likelihood function as a function of λ and determines the maximum likelihood estimate with confidence bounds.\n",
    "\n",
    "**Mathematical Steps:**\n",
    "\n",
    "1. **Create λ range**: If not provided, use a range around the sample mean\n",
    "2. **Calculate likelihood curve**: For each λ value, compute L(λ) using your function from part (a)\n",
    "3. **Find MLE**: The λ value that maximizes the likelihood\n",
    "4. **Determine confidence bounds**: \n",
    "   - Find the maximum likelihood: $L_{\\max} = L(\\hat{\\lambda})$\n",
    "   - The 1σ confidence interval corresponds to $L(\\lambda) = L_{\\max} \\times e^{-0.5}$ (where log-likelihood drops by 0.5)\n",
    "   - Find the λ values where the likelihood curve crosses this threshold\n",
    "\n",
    "**Requirements:**\n",
    "- Use your `poisson_likelihood` function from part (a) to compute likelihoods\n",
    "- Create a smooth curve by evaluating many λ values\n",
    "- Plot the likelihood vs λ with appropriate labels and formatting\n",
    "- Mark the MLE and confidence bounds on the plot\n",
    "- Return the figure object and the three key values\n",
    "\n",
    "**Parameters:**\n",
    "- `data`: array-like, observed count data\n",
    "- `lambda_range`: tuple (min, max), default None. If None, use (0.5*mean, 2*mean)\n",
    "- `n_points`: int, default 100, number of λ values to evaluate\n",
    "- `show_plot`: bool, default False. If True, call `plt.show()`\n",
    "\n",
    "**Returns:**\n",
    "- `(fig, mle, lower_bound, upper_bound)`: tuple containing:\n",
    "  - `fig`: matplotlib figure object\n",
    "  - `mle`: float, maximum likelihood estimate of λ\n",
    "  - `lower_bound`: float, 1σ lower confidence bound\n",
    "  - `upper_bound`: float, 1σ upper confidence bound\n",
    "\n",
    "**Note:** For computational stability with small likelihoods, you may want to work with log-likelihood internally and convert back for plotting and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7da044",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_likelihood_curve(data, lambda_range=None, n_points=100, show_plot=False):\n",
    "    data = np.array(data)\n",
    "    sample_mean = np.mean(data)\n",
    "    \n",
    "    # Set lambda range if not provided\n",
    "    if lambda_range is None:\n",
    "        lambda_range = ...\n",
    "    \n",
    "    # Create array of lambda values\n",
    "    lambda_vals = ...\n",
    "    \n",
    "    # Calculate likelihood for each lambda value\n",
    "    likelihoods = ...\n",
    "    \n",
    "    # Find MLE\n",
    "    mle = ...\n",
    "    \n",
    "    # Find confidence bounds (likelihood drops by e^(-0.5))\n",
    "    threshold = ...\n",
    "    lower_bound = ...\n",
    "    upper_bound = ...\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot likelihood curve and mark MLE and bounds\n",
    "    ...\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig, mle, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036692ca",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate sample Poisson data for testing\n",
    "np.random.seed(rng_seed)\n",
    "\n",
    "# Create a dataset with known Poisson parameter (lambda = 4.2)\n",
    "true_lambda = 4.2\n",
    "n_observations = 50\n",
    "poisson_data = np.random.poisson(true_lambda, n_observations)\n",
    "\n",
    "print(f\"Generated {n_observations} observations from Poisson(λ={true_lambda})\")\n",
    "print(f\"Sample data: {poisson_data[:10]}...\")  # Show first 10 values\n",
    "print(f\"Sample mean: {np.mean(poisson_data):.3f}\")\n",
    "print(f\"Sample standard deviation: {np.std(poisson_data):.3f}\")\n",
    "print(f\"Theoretical mean: {true_lambda}\")\n",
    "print(f\"Theoretical std: {np.sqrt(true_lambda):.3f}\")\n",
    "\n",
    "# Test the likelihood function with a few values\n",
    "print(f\"\\nTesting likelihood function:\")\n",
    "test_lambdas = [3.0, 4.0, 5.0]\n",
    "for lam in test_lambdas:\n",
    "    likelihood = poisson_likelihood(poisson_data, lam)\n",
    "    print(f\"L(λ={lam}) = {likelihood:.2e}\")\n",
    "\n",
    "# Plot the likelihood curve\n",
    "fig, mle, lower, upper = plot_likelihood_curve(poisson_data, show_plot=True)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Maximum Likelihood Estimate: {mle:.3f}\")\n",
    "print(f\"1σ Confidence Interval: [{lower:.3f}, {upper:.3f}]\")\n",
    "print(f\"True value λ={true_lambda} is {'within' if lower <= true_lambda <= upper else 'outside'} the confidence interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85a5ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41a284",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Required disclosure of use of AI technology\n",
    "\n",
    "Please indicate whether you used AI to complete this homework. If you did, explain how you used it in the python cell below, as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0425073f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# write ai disclosure here:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174aacae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Upload the .zip file to Gradescope!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63fdfc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fd53a",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otter_grading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> result = sample_uniform_mean(0, 10, 1000)\n>>> is_number = isinstance(result, (int, float, np.floating))\n>>> in_range = 0 <= result <= 10\n>>> reasonable_mean = 3 <= result <= 7\n>>> (is_number, bool(in_range), bool(reasonable_mean))\n(True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> result = sample_gamma_mean(2, 2, 1000)\n>>> is_number = isinstance(result, (int, float, np.floating))\n>>> positive = result > 0\n>>> reasonable_mean = 2 <= result <= 6\n>>> (is_number, bool(positive), bool(reasonable_mean))\n(True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.random.seed(42)\n>>> fig = plot_sample_means(use_uniform=True, N=50, n_samples=100, show_plot=False)\n>>> import matplotlib.figure\n>>> test_result = isinstance(fig, matplotlib.figure.Figure)\n>>> plt.close(fig)\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> fig = plot_sample_means(use_uniform=True, N=100, n_samples=50, show_plot=False)\n>>> ax = fig.axes[0]\n>>> has_histogram = len(ax.patches) > 0\n>>> has_xlabel = ax.get_xlabel() == 'Sample Mean'\n>>> has_ylabel = ax.get_ylabel() == 'Density'\n>>> title = ax.get_title()\n>>> has_clt_in_title = 'Central Limit Theorem' in title\n>>> has_grid = ax.xaxis.get_gridlines()[0].get_visible()\n>>> plt.close(fig)\n>>> (has_histogram, has_xlabel, has_ylabel, has_clt_in_title, has_grid)\n(True, True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> result = projectile_range_with_error(50, 2, np.pi / 4, 0.05)\n>>> is_tuple = isinstance(result, tuple)\n>>> has_two_elements = len(result) == 2\n>>> both_numbers = all((isinstance(x, (int, float, np.floating)) for x in result))\n>>> R, sigma_R = result\n>>> positive_values = R > 0 and sigma_R > 0\n>>> (is_tuple, has_two_elements, both_numbers, bool(positive_values))\n(True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> R_45, _ = projectile_range_with_error(40, 1, np.pi / 4, 0.01)\n>>> R_30, _ = projectile_range_with_error(40, 1, np.pi / 6, 0.01)\n>>> R_60, _ = projectile_range_with_error(40, 1, np.pi / 3, 0.01)\n>>> max_at_45 = R_45 > R_30 and R_45 > R_60\n>>> reasonable_range = 150 < R_45 < 170\n>>> (bool(max_at_45), bool(reasonable_range))\n(True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> result = pendulum_period_with_error(0.1, 0.005, 2.0, 0.05, 0.5, 0.01)\n>>> is_tuple = isinstance(result, tuple)\n>>> has_two_elements = len(result) == 2\n>>> both_numbers = all((isinstance(x, (int, float, np.floating)) for x in result))\n>>> T, sigma_T = result\n>>> positive_values = T > 0 and sigma_T > 0\n>>> (is_tuple, has_two_elements, both_numbers, bool(positive_values))\n(True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> T1, _ = pendulum_period_with_error(0.1, 0.001, 1.0, 0.01, 0.3, 0.005)\n>>> T2, _ = pendulum_period_with_error(0.2, 0.001, 1.0, 0.01, 0.3, 0.005)\n>>> T3, _ = pendulum_period_with_error(0.1, 0.001, 2.0, 0.01, 0.3, 0.005)\n>>> T4, _ = pendulum_period_with_error(0.1, 0.001, 1.0, 0.01, 0.6, 0.005)\n>>> larger_I_increases_T = T2 > T1\n>>> larger_m_decreases_T = T3 < T1\n>>> larger_d_decreases_T = T4 < T1\n>>> reasonable_periods = all((0.5 < T < 5.0 for T in [T1, T2, T3, T4]))\n>>> (bool(larger_I_increases_T), bool(larger_m_decreases_T), bool(larger_d_decreases_T), reasonable_periods)\n(True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> result = analyze_covariance('physics_data.csv')\n>>> is_tuple = isinstance(result, tuple)\n>>> has_two_elements = len(result) == 2\n>>> cov_matrix, corr_matrix = result\n>>> both_numpy = isinstance(cov_matrix, np.ndarray) and isinstance(corr_matrix, np.ndarray)\n>>> correct_shape = cov_matrix.shape == (7, 7) and corr_matrix.shape == (7, 7)\n>>> (is_tuple, has_two_elements, both_numpy, correct_shape)\n(True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> cov_matrix, corr_matrix = analyze_covariance('physics_data.csv')\n>>> diagonal_ones = np.allclose(np.diag(corr_matrix), 1.0)\n>>> valid_range = np.all((-1 <= corr_matrix) & (corr_matrix <= 1))\n>>> is_symmetric = np.allclose(corr_matrix, corr_matrix.T)\n>>> has_correlations = np.any(np.abs(corr_matrix - np.eye(7)) > 0.3)\n>>> (diagonal_ones, bool(valid_range), is_symmetric, bool(has_correlations))\n(True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fig = plot_covariance_matrices('physics_data.csv', show_plot=False)\n>>> is_figure = isinstance(fig, matplotlib.figure.Figure)\n>>> has_two_subplots = len(fig.axes) == 4\n>>> plt.close(fig)\n>>> (is_figure, has_two_subplots)\n(True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> fig = plot_covariance_matrices('physics_data.csv', show_plot=False)\n>>> ax1, ax2 = (fig.axes[0], fig.axes[1])\n>>> has_cov_title = 'Covariance' in ax1.get_title()\n>>> has_corr_title = 'Correlation' in ax2.get_title()\n>>> has_cov_image = len(ax1.images) > 0\n>>> has_corr_image = len(ax2.images) > 0\n>>> has_labels = ax1.get_xlabel() != '' and ax2.get_xlabel() != ''\n>>> plt.close(fig)\n>>> (has_cov_title, has_corr_title, has_cov_image, has_corr_image, has_labels)\n(True, True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> test_data = [2, 3, 1, 4, 2]\n>>> result = poisson_likelihood(test_data, 2.5)\n>>> is_number = isinstance(result, (int, float, np.floating))\n>>> is_positive = result > 0\n>>> reasonable_magnitude = 0 < result < 1\n>>> (is_number, bool(is_positive), bool(reasonable_magnitude))\n(True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> test_data = [3, 2, 4, 3, 2, 3, 4, 1, 3, 5]\n>>> likelihood_3 = poisson_likelihood(test_data, 3.0)\n>>> likelihood_1 = poisson_likelihood(test_data, 1.0)\n>>> likelihood_6 = poisson_likelihood(test_data, 6.0)\n>>> better_than_1 = likelihood_3 > likelihood_1\n>>> better_than_6 = likelihood_3 > likelihood_6\n>>> bool(better_than_1 and better_than_6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> test_data = np.random.poisson(3.5, 30)\n>>> result = plot_likelihood_curve(test_data, show_plot=False)\n>>> is_tuple = isinstance(result, tuple)\n>>> has_four_elements = len(result) == 4\n>>> fig, mle, lower, upper = result\n>>> is_figure = isinstance(fig, matplotlib.figure.Figure)\n>>> all_numbers = all((isinstance(x, (int, float, np.floating)) for x in [mle, lower, upper]))\n>>> plt.close(fig)\n>>> (is_tuple, has_four_elements, is_figure, all_numbers)\n(True, True, True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> test_data = np.random.poisson(4.0, 50)\n>>> fig, mle, lower, upper = result = plot_likelihood_curve(test_data, show_plot=False)\n>>> sample_mean = np.mean(test_data)\n>>> mle_close_to_mean = abs(mle - sample_mean) < 0.5\n>>> bounds_bracket_mle = lower < mle < upper\n>>> plt.close(fig)\n>>> (bool(mle_close_to_mean), bool(bounds_bracket_mle))\n(True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
