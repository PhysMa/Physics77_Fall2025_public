{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2e442",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ws7.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef10a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49644c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "#below line allows matplotlib plots to appear in cell output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef3b266",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 1**: F-Test for Comparing Population Means\n",
    "\n",
    "In this question, you'll implement an F-test to compare the means of multiple normally distributed datasets. The F-test is a statistical hypothesis test that determines whether two or more groups have significantly different means by comparing their variances.\n",
    "\n",
    "### Background: F-Test Theory\n",
    "\n",
    "The F-test for comparing means is based on analysis of variance (ANOVA) principles. When comparing two groups, we test the null hypothesis that both groups have the same population mean (μ₁ = μ₂) against the alternative hypothesis that they have different means (μ₁ ≠ μ₂).\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "The F-statistic compares the **between-group variability** to the **within-group variability**:\n",
    "\n",
    "$$F = \\frac{\\text{explained variance}}{\\text{unexplained variance}} = \\frac{\\text{between-group variability}}{\\text{within-group variability}}$$\n",
    "\n",
    "**For two groups with sample sizes n₁ and n₂:**\n",
    "\n",
    "**Between-group variability (explained variance):**\n",
    "$$\\text{MS}_{\\text{between}} = \\frac{n_1(\\bar{Y}_1 - \\bar{Y})^2 + n_2(\\bar{Y}_2 - \\bar{Y})^2}{K-1}$$\n",
    "\n",
    "where $\\bar{Y}_1$ and $\\bar{Y}_2$ are the sample means of groups 1 and 2, $\\bar{Y}$ is the overall mean, and K = 2 (number of groups).\n",
    "\n",
    "**Within-group variability (unexplained variance):**\n",
    "$$\\text{MS}_{\\text{within}} = \\frac{\\sum_{i=1}^{n_1}(Y_{1i} - \\bar{Y}_1)^2 + \\sum_{i=1}^{n_2}(Y_{2i} - \\bar{Y}_2)^2}{N-K}$$\n",
    "\n",
    "where N = n₁ + n₂ is the total sample size.\n",
    "\n",
    "**F-statistic:**\n",
    "$$F = \\frac{\\text{MS}_{\\text{between}}}{\\text{MS}_{\\text{within}}}$$\n",
    "\n",
    "**Interpretation:**\n",
    "- **F > 1**: Between-group variation exceeds within-group variation → groups may have different means\n",
    "- **F ≈ 1**: Between-group and within-group variations are similar → groups likely have the same mean\n",
    "- **F < 1**: Within-group variation exceeds between-group variation → very strong evidence groups have the same mean\n",
    "\n",
    "**Note**: Unlike the traditional F-test for comparing variances, the ANOVA F-statistic can be less than 1. When F < 1, it indicates that the variation between group means is smaller than the typical variation within groups, providing strong evidence that the population means are equal.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Write a function `find_most_similar_means(filename)` that:\n",
    "1. Loads data from a CSV file containing multiple normally distributed datasets\n",
    "2. Performs F-tests between every pair of datasets using ANOVA formulation\n",
    "3. Returns the names of the two datasets most likely to have the same population mean (smallest F-statistic)\n",
    "\n",
    "**Requirements:**\n",
    "- Load the CSV file using `pd.read_csv(filename)`\n",
    "- For each pair of datasets, calculate the F-statistic using the ANOVA formulation above\n",
    "- Use `np.mean()` to calculate sample means and overall mean\n",
    "- Calculate between-group and within-group mean squares as defined above\n",
    "- Find the pair with the **smallest** F-statistic (most likely to have equal means)\n",
    "- Return a tuple containing the two dataset names as strings\n",
    "\n",
    "**Parameters:**\n",
    "- `filename`: string, path to the CSV file containing the datasets (`ftest_data.csv`)\n",
    "\n",
    "**Returns:**\n",
    "- `result`: tuple of two strings, names of the datasets most likely to have the same mean\n",
    "\n",
    "**Example:**\n",
    "If datasets 'dataset_A' and 'dataset_E' have the smallest F-statistic, return `('dataset_A', 'dataset_E')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5305479",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def find_most_similar_means(filename):\n",
    "    # Load the data\n",
    "    data = ...\n",
    "    \n",
    "    # Get dataset names\n",
    "    dataset_names = data.columns.tolist()\n",
    "    \n",
    "    # Initialize min F statistic tracking variables\n",
    "    ...\n",
    "    \n",
    "    # Compare every pair of datasets with a nested for loop\n",
    "    ...\n",
    "    \n",
    "            \n",
    "    return best_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec750a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461bd12e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 2**: Error Propagation and Uncertainty Visualization\n",
    "\n",
    "In this question, you'll implement error propagation formulas to compute uncertainties in derived quantities and visualize the results with error bars.\n",
    "\n",
    "### Background: Error Propagation Theory\n",
    "\n",
    "When we have a function y = g(x₁, x₂, ..., xₙ) and we know the uncertainties σ₁, σ₂, ..., σₙ in the input parameters x₁, x₂, ..., xₙ, we can calculate the uncertainty σᵧ in the output y using the **error propagation formula**:\n",
    "\n",
    "$$\\sigma_y = \\sqrt{\\sum_{i=1}^{n} \\left(\\frac{\\partial g}{\\partial x_i}\\right)^2 \\sigma_i^2}$$\n",
    "\n",
    "This formula assumes that the uncertainties in the input parameters are uncorrelated and small compared to the parameter values themselves.\n",
    "\n",
    "**Steps for error propagation:**\n",
    "1. Calculate the partial derivatives ∂g/∂xᵢ for each input parameter\n",
    "2. Evaluate these derivatives at the measured parameter values\n",
    "3. Apply the error propagation formula above\n",
    "\n",
    "### Part a: Function with Error Propagation\n",
    "\n",
    "Consider the **ideal gas law**. The temperature T of an ideal gas can be calculated from pressure P, volume V, and number of moles n using:\n",
    "\n",
    "$$T = \\frac{PV}{nR}$$\n",
    "\n",
    "where R = 8.314 J/(mol·K) is the universal gas constant.\n",
    "\n",
    "Write a function `gas_temperature_with_error(P, V, n, sigma_P, sigma_V, sigma_n, R=8.314)` that:\n",
    "1. Calculates the temperature T using the ideal gas law above\n",
    "2. Computes the uncertainty σₜ in the temperature using error propagation\n",
    "3. Returns both the temperature and its uncertainty\n",
    "\n",
    "**Requirements:**\n",
    "- The function should be vectorized (work with numpy arrays)\n",
    "- Calculate the partial derivatives analytically: ∂T/∂P, ∂T/∂V, ∂T/∂n\n",
    "- Apply the error propagation formula: σₜ = √[(∂T/∂P)²σₚ² + (∂T/∂V)²σᵥ² + (∂T/∂n)²σₙ²]\n",
    "- Use `np.sqrt()` for vectorized operations\n",
    "\n",
    "**Parameters:**\n",
    "- `P`: float or array, pressure (Pa)\n",
    "- `V`: float or array, volume (m³)\n",
    "- `n`: float or array, number of moles (mol)\n",
    "- `sigma_P`: float or array, uncertainty in pressure (Pa)\n",
    "- `sigma_V`: float or array, uncertainty in volume (m³)\n",
    "- `sigma_n`: float or array, uncertainty in number of moles (mol)\n",
    "- `R`: float, universal gas constant (default 8.314 J/(mol·K))\n",
    "\n",
    "**Returns:**\n",
    "- `T`: float or array, temperature (K)\n",
    "- `sigma_T`: float or array, uncertainty in temperature (K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651301e",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def gas_temperature_with_error(P, V, n, sigma_P, sigma_V, sigma_n, R=8.314):\n",
    "    # Calculate the temperature\n",
    "    \n",
    "    # Calculate partial derivatives\n",
    "    # dT_dP = ...\n",
    "    # dT_dV = ...\n",
    "    # dT_dn = ...\n",
    "    \n",
    "    # Apply error propagation formula\n",
    "    ...\n",
    "    \n",
    "    return (T, sigma_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58452552",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d7ac5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part b: Error Bar Plotting\n",
    "\n",
    "Write a function `plot_temperature_vs_pressure(pressures, volumes, n_moles, sigma_P, sigma_V, sigma_n, show_plot=False)` that creates a plot of gas temperature versus pressure with error bars in both x and y directions.\n",
    "\n",
    "**Requirements:**\n",
    "- Use the `gas_temperature_with_error()` function from Part 2a to calculate temperatures and their uncertainties\n",
    "- Use `plt.errorbar()` to plot the data with error bars in both directions\n",
    "- Set appropriate axis labels and title, and plot x and y error\n",
    "- Configure the plot appearance:\n",
    "  - Use `'o'` markers with `markersize=6`\n",
    "  - Set `capsize=5` for error bar caps\n",
    "  - Use `linewidth=2` for connecting lines\n",
    "  - Add a grid with `alpha=0.3`\n",
    "- Labels and formatting:\n",
    "  - X-axis: \"Pressure (Pa)\"\n",
    "  - Y-axis: \"Temperature (K)\"\n",
    "  - Title: \"Gas Temperature vs Pressure\"\n",
    "- Only call `plt.show()` if `show_plot=True`\n",
    "- Return the matplotlib figure object\n",
    "\n",
    "**Parameters:**\n",
    "- `pressures`: array, pressure values (Pa)\n",
    "- `volumes`: array, volume values (m³)\n",
    "- `n_moles`: array, number of moles (mol)\n",
    "- `sigma_P`: array, uncertainties in pressure (Pa)\n",
    "- `sigma_V`: array, uncertainties in volume (m³)\n",
    "- `sigma_n`: array, uncertainties in number of moles (mol)\n",
    "- `show_plot`: bool, default False. If True, call `plt.show()`\n",
    "\n",
    "**Returns:**\n",
    "- `fig`: matplotlib figure object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4caf3d",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_temperature_vs_pressure(pressures, volumes, n_moles, sigma_P, sigma_V, sigma_n, show_plot=False):\n",
    "    # Calculate temperatures and uncertainties using gas_temperature_with_error\n",
    "    temperatures, sigma_T = ...\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot with error bars using plt.errorbar (both xerr and yerr)\n",
    "    \n",
    "    # Set labels and formatting\n",
    "    \n",
    "    # Show plot if requested\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834362d3",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate sample data to test the plotting function\n",
    "np.random.seed(rng_seed)\n",
    "\n",
    "# Create arrays for gas law parameters with uncertainties\n",
    "pressures = np.linspace(80000, 120000, 8)  # Pa\n",
    "volumes = np.linspace(0.020, 0.030, 8)  # m³\n",
    "n_moles = np.linspace(0.8, 1.2, 8)  # mol\n",
    "\n",
    "# Define uncertainties for each parameter\n",
    "sigma_P = np.full_like(pressures, 1000.0)  # Pa\n",
    "sigma_V = np.full_like(volumes, 0.0005)  # m³\n",
    "sigma_n = np.full_like(n_moles, 0.01)  # mol\n",
    "\n",
    "# Plot the results using the new function signature\n",
    "fig1 = plot_temperature_vs_pressure(pressures, volumes, n_moles, sigma_P, sigma_V, sigma_n, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9fa5d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c40927",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 3**: Generating Correlated Data\n",
    "\n",
    "In this question, you'll create a function that generates synthetic datasets with specified correlation properties. Understanding and controlling correlations between variables is crucial in data science, machine learning, and experimental design.\n",
    "\n",
    "### Background: Correlation and Covariance\n",
    "\n",
    "**Correlation** measures the linear relationship between two variables. The Pearson correlation coefficient r ranges from -1 to +1:\n",
    "- **r = +1**: Perfect positive linear correlation\n",
    "- **r = 0**: No linear correlation  \n",
    "- **r = -1**: Perfect negative linear correlation\n",
    "\n",
    "The **correlation matrix** is a symmetric matrix where element (i,j) represents the correlation between variables i and j. The diagonal elements are always 1 (perfect self-correlation).\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "Write a function `generate_correlated_data(N, rng_seed=42)` that generates synthetic data with the following correlation structure:\n",
    "- **Feature 1 and Feature 2**: Positive correlation (r > 0)\n",
    "- **Feature 3 and Feature 1**: Near-zero correlation (|r| ≈ 0)\n",
    "- **Feature 3 and Feature 2**: Near-zero correlation (|r| ≈ 0)\n",
    "\n",
    "**Requirements:**\n",
    "- Generate N data points for each of 3 features\n",
    "- Use `np.random` methods with the provided random seed for reproducibility\n",
    "- Return three arrays of length N: `feature1`, `feature2`, `feature3`\n",
    "- Features 1 and 2 should have a clear positive correlation\n",
    "- Feature 3 should be approximately uncorrelated with both features 1 and 2\n",
    "\n",
    "**Approach suggestions:**\n",
    "- Start with independent random variables\n",
    "- Transform them to create desired correlations\n",
    "- Consider methods like linear combinations, multivariate normal distributions, or other correlation-inducing transformations\n",
    "\n",
    "**Parameters:**\n",
    "- `N`: int, number of data points to generate\n",
    "- `rng_seed`: int, random seed for reproducibility (default 42)\n",
    "\n",
    "**Returns:**\n",
    "- `feature1`: array of length N, first feature\n",
    "- `feature2`: array of length N, second feature (positively correlated with feature1)\n",
    "- `feature3`: array of length N, third feature (uncorrelated with features 1 and 2)\n",
    "\n",
    "A helper function `plot_correlations(feature1, feature2, feature3)` is provided below to visualize your results and compute the correlation matrix for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f73458",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# PROVIDED HELPER FUNCTION - DO NOT MODIFY\n",
    "def plot_correlations(feature1, feature2, feature3):\n",
    "    \"\"\"\n",
    "    Create correlation plots and return the correlation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    feature1 : array\n",
    "        First feature data\n",
    "    feature2 : array  \n",
    "        Second feature data\n",
    "    feature3 : array\n",
    "        Third feature data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    correlation_matrix : ndarray\n",
    "        3x3 correlation matrix between the three features\n",
    "    \"\"\"\n",
    "    # Combine features into a single array for correlation calculation\n",
    "    data = np.column_stack([feature1, feature2, feature3])\n",
    "    correlation_matrix = np.corrcoef(data.T)\n",
    "    \n",
    "    # Create subplot figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Plot pairwise scatter plots\n",
    "    axes[0, 0].scatter(feature1, feature2, alpha=0.6, s=20)\n",
    "    axes[0, 0].set_xlabel('Feature 1')\n",
    "    axes[0, 0].set_ylabel('Feature 2')\n",
    "    axes[0, 0].set_title(f'Features 1 vs 2 (r = {correlation_matrix[0,1]:.3f})')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].scatter(feature1, feature3, alpha=0.6, s=20)\n",
    "    axes[0, 1].set_xlabel('Feature 1')\n",
    "    axes[0, 1].set_ylabel('Feature 3')\n",
    "    axes[0, 1].set_title(f'Features 1 vs 3 (r = {correlation_matrix[0,2]:.3f})')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].scatter(feature2, feature3, alpha=0.6, s=20)\n",
    "    axes[1, 0].set_xlabel('Feature 2')\n",
    "    axes[1, 0].set_ylabel('Feature 3')\n",
    "    axes[1, 0].set_title(f'Features 2 vs 3 (r = {correlation_matrix[1,2]:.3f})')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot correlation matrix as heatmap\n",
    "    im = axes[1, 1].imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    axes[1, 1].set_title('Correlation Matrix')\n",
    "    axes[1, 1].set_xticks([0, 1, 2])\n",
    "    axes[1, 1].set_yticks([0, 1, 2])\n",
    "    axes[1, 1].set_xticklabels(['Feature 1', 'Feature 2', 'Feature 3'])\n",
    "    axes[1, 1].set_yticklabels(['Feature 1', 'Feature 2', 'Feature 3'])\n",
    "    \n",
    "    # Add correlation values as text\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axes[1, 1].text(j, i, f'{correlation_matrix[i,j]:.3f}', \n",
    "                           ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=axes[1, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d97d5",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_correlated_data(N, rng_seed=42):\n",
    "    # Set the random seed for reproducibility\n",
    "    np.random.seed(rng_seed)\n",
    "    \n",
    "    # Generate feature1 (base feature)\n",
    "    feature1 = ...\n",
    "    \n",
    "    # Generate feature2 (positively correlated with feature1)\n",
    "    # Hint: Use a linear combination or transformation\n",
    "    feature2 = ...\n",
    "    \n",
    "    # Generate feature3 (uncorrelated with features 1 and 2)\n",
    "    feature3 = ...\n",
    "    \n",
    "    return feature1, feature2, feature3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cb581",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Generate sample data to test the function\n",
    "np.random.seed(rng_seed)  \n",
    "\n",
    "# Generate dataset with N=500 points\n",
    "feature1, feature2, feature3 = generate_correlated_data(500, rng_seed=rng_seed)\n",
    "\n",
    "print(f\"Generated {len(feature1)} data points for each feature\")\n",
    "print(f\"Feature 1: mean = {np.mean(feature1):.3f}, std = {np.std(feature1):.3f}\")\n",
    "print(f\"Feature 2: mean = {np.mean(feature2):.3f}, std = {np.std(feature2):.3f}\")\n",
    "print(f\"Feature 3: mean = {np.mean(feature3):.3f}, std = {np.std(feature3):.3f}\")\n",
    "\n",
    "# Plot correlations and get correlation matrix\n",
    "correlation_matrix = plot_correlations(feature1, feature2, feature3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d2159",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3ef9a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Required disclosure of use of AI technology\n",
    "\n",
    "Please indicate whether you used AI to complete this homework. If you did, explain how you used it in the python cell below, as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d988e0",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# write ai disclosure here:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ffc386",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Upload the .zip file to Gradescope!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ceddb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31c31b",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otter_grading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> result = find_most_similar_means('ftest_data.csv')\n>>> test_result = isinstance(result, tuple) and len(result) == 2 and isinstance(result[0], str) and isinstance(result[1], str)\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> data = pd.read_csv('ftest_data.csv')\n>>> valid_names = set(data.columns)\n>>> result = find_most_similar_means('ftest_data.csv')\n>>> test_result = result[0] in valid_names and result[1] in valid_names and (result[0] != result[1])\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> data = pd.read_csv('ftest_data.csv')\n>>> dataset_names = data.columns.tolist()\n>>> min_f_stat = float('inf')\n>>> expected_pair = None\n>>> for i in range(len(dataset_names)):\n...     for j in range(i + 1, len(dataset_names)):\n...         group1 = data[dataset_names[i]]\n...         group2 = data[dataset_names[j]]\n...         n1, n2 = (len(group1), len(group2))\n...         N = n1 + n2\n...         K = 2\n...         y1_bar = np.mean(group1)\n...         y2_bar = np.mean(group2)\n...         y_overall = (n1 * y1_bar + n2 * y2_bar) / N\n...         ms_between = (n1 * (y1_bar - y_overall) ** 2 + n2 * (y2_bar - y_overall) ** 2) / (K - 1)\n...         ss_within = np.sum((group1 - y1_bar) ** 2) + np.sum((group2 - y2_bar) ** 2)\n...         ms_within = ss_within / (N - K)\n...         f_stat = ms_between / ms_within if ms_within > 0 else float('inf')\n...         if f_stat < min_f_stat:\n...             min_f_stat = f_stat\n...             expected_pair = (dataset_names[i], dataset_names[j])\n>>> actual_result = find_most_similar_means('ftest_data.csv')\n>>> test_result = set(actual_result) == set(expected_pair)\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> test_data = pd.DataFrame({'A': [1, 2, 3, 4, 5], 'B': [10, 20, 30, 40, 50], 'C': [2, 3, 4, 5, 6]})\n>>> test_data.to_csv('test_ftest.csv', index=False)\n>>> result = find_most_similar_means('test_ftest.csv')\n>>> test_result = set(result) == {'A', 'C'}\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> P_test = 100000.0\n>>> V_test = 0.02\n>>> n_test = 1.0\n>>> sigma_P_test = 1000.0\n>>> sigma_V_test = 0.0005\n>>> sigma_n_test = 0.01\n>>> result = gas_temperature_with_error(P_test, V_test, n_test, sigma_P_test, sigma_V_test, sigma_n_test)\n>>> test_result = isinstance(result, tuple) and len(result) == 2\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> P_array = np.array([80000, 120000])\n>>> V_array = np.array([0.015, 0.025])\n>>> n_array = np.array([0.8, 1.2])\n>>> sigma_P_array = np.array([800, 1200])\n>>> sigma_V_array = np.array([0.0003, 0.0006])\n>>> sigma_n_array = np.array([0.008, 0.012])\n>>> T_result, sigma_T_result = gas_temperature_with_error(P_array, V_array, n_array, sigma_P_array, sigma_V_array, sigma_n_array)\n>>> test_result = isinstance(T_result, np.ndarray) and isinstance(sigma_T_result, np.ndarray) and (len(T_result) == 2) and (len(sigma_T_result) == 2)\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> P_known = 101325.0\n>>> V_known = 0.0224\n>>> n_known = 1.0\n>>> sigma_P_known = 500.0\n>>> sigma_V_known = 0.0002\n>>> sigma_n_known = 0.005\n>>> T_calc, sigma_T_calc = gas_temperature_with_error(P_known, V_known, n_known, sigma_P_known, sigma_V_known, sigma_n_known)\n>>> expected_T = P_known * V_known / (n_known * 8.314)\n>>> test_temperature = abs(T_calc - expected_T) < 0.1\n>>> test_uncertainty = sigma_T_calc > 0 and sigma_T_calc < T_calc\n>>> test_result = test_temperature and test_uncertainty\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> P_edge = 80000.0\n>>> V_edge = 0.03\n>>> n_edge = 1.5\n>>> sigma_P_zero = 0.0\n>>> sigma_V_zero = 0.0\n>>> sigma_n_zero = 0.0\n>>> T_edge, sigma_T_edge = gas_temperature_with_error(P_edge, V_edge, n_edge, sigma_P_zero, sigma_V_zero, sigma_n_zero)\n>>> test_result = sigma_T_edge == 0.0\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_pressures = np.array([80000, 90000, 100000])\n>>> test_volumes = np.array([0.02, 0.025, 0.03])\n>>> test_n_moles = np.array([0.8, 1.0, 1.2])\n>>> test_sigma_P = np.array([1000, 1100, 1200])\n>>> test_sigma_V = np.array([0.0005, 0.0006, 0.0007])\n>>> test_sigma_n = np.array([0.01, 0.011, 0.012])\n>>> fig_test = plot_temperature_vs_pressure(test_pressures, test_volumes, test_n_moles, test_sigma_P, test_sigma_V, test_sigma_n)\n>>> import matplotlib.figure\n>>> test_result = isinstance(fig_test, matplotlib.figure.Figure)\n>>> plt.close(fig_test)\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> test_pressures = np.array([80000, 90000, 100000, 110000])\n>>> test_volumes = np.array([0.02, 0.025, 0.03, 0.035])\n>>> test_n_moles = np.array([0.8, 1.0, 1.2, 1.4])\n>>> test_sigma_P = np.array([800, 900, 1000, 1100])\n>>> test_sigma_V = np.array([0.0004, 0.0005, 0.0006, 0.0007])\n>>> test_sigma_n = np.array([0.008, 0.01, 0.012, 0.014])\n>>> fig_components = plot_temperature_vs_pressure(test_pressures, test_volumes, test_n_moles, test_sigma_P, test_sigma_V, test_sigma_n)\n>>> ax = fig_components.axes[0]\n>>> has_errorbars = len(ax.collections) >= 2\n>>> has_xlabel = ax.get_xlabel() == 'Pressure (Pa)'\n>>> has_ylabel = ax.get_ylabel() == 'Temperature (K)'\n>>> has_title = ax.get_title() == 'Gas Temperature vs Pressure'\n>>> plt.close(fig_components)\n>>> test_result = has_errorbars and has_xlabel and has_ylabel and has_title\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> test_pressures = np.array([70000, 90000, 110000])\n>>> test_volumes = np.array([0.018, 0.025, 0.032])\n>>> test_n_moles = np.array([0.7, 1.0, 1.3])\n>>> test_sigma_P = np.array([700, 900, 1100])\n>>> test_sigma_V = np.array([0.0004, 0.0005, 0.0006])\n>>> test_sigma_n = np.array([0.007, 0.01, 0.013])\n>>> fig_format = plot_temperature_vs_pressure(test_pressures, test_volumes, test_n_moles, test_sigma_P, test_sigma_V, test_sigma_n)\n>>> ax = fig_format.axes[0]\n>>> has_grid = ax.xaxis.get_gridlines()[0].get_visible()\n>>> has_legend = ax.get_legend() is not None\n>>> plt.close(fig_format)\n>>> test_result = has_grid and has_legend\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> test_pressures = np.array([90000, 100000, 110000])\n>>> test_volumes = np.array([0.022, 0.025, 0.028])\n>>> test_n_moles = np.array([0.9, 1.0, 1.1])\n>>> test_sigma_P = np.array([900, 1000, 1100])\n>>> test_sigma_V = np.array([0.0004, 0.0005, 0.0006])\n>>> test_sigma_n = np.array([0.009, 0.01, 0.011])\n>>> fig_realistic = plot_temperature_vs_pressure(test_pressures, test_volumes, test_n_moles, test_sigma_P, test_sigma_V, test_sigma_n)\n>>> expected_temps, expected_uncertainties = gas_temperature_with_error(test_pressures, test_volumes, test_n_moles, test_sigma_P, test_sigma_V, test_sigma_n)\n>>> ax = fig_realistic.axes[0]\n>>> has_data = len(ax.lines) > 0 or len(ax.collections) > 0\n>>> has_both_errorbars = len(ax.collections) >= 2\n>>> plt.close(fig_realistic)\n>>> test_result = has_data and has_both_errorbars and (len(expected_temps) == 3)\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> N_test = 100\n>>> f1, f2, f3 = generate_correlated_data(N_test, rng_seed=42)\n>>> test_result = isinstance(f1, np.ndarray) and isinstance(f2, np.ndarray) and isinstance(f3, np.ndarray) and (len(f1) == N_test) and (len(f2) == N_test) and (len(f3) == N_test)\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> N_test = 2000\n>>> f1, f2, f3 = generate_correlated_data(N_test, rng_seed=42)\n>>> correlation_12 = np.corrcoef(f1, f2)[0, 1]\n>>> test_result = correlation_12 > 0\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> N_test = 2000\n>>> f1, f2, f3 = generate_correlated_data(N_test, rng_seed=42)\n>>> correlation_13 = np.corrcoef(f1, f3)[0, 1]\n>>> correlation_23 = np.corrcoef(f2, f3)[0, 1]\n>>> tolerance = 0.1\n>>> test_13 = abs(correlation_13) < tolerance\n>>> test_23 = abs(correlation_23) < tolerance\n>>> test_result = test_13 and test_23\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
