{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c08827",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw11.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f03081",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f091db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "#below line allows matplotlib plots to appear in cell output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885ef64",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# **Question 1**: Image Compression with 2D Fourier Transforms\n",
    "\n",
    "In this question, you'll explore how 2D Fourier transforms can be used to analyze and compress digital images. The Fourier transform decomposes an image into its frequency components, allowing us to understand which spatial frequencies contribute most to the image content.\n",
    "\n",
    "### Background: 2D Fourier Transforms for Images\n",
    "\n",
    "A color image can be represented as a 3D array with dimensions `(height, width, 3)`, where the last dimension corresponds to the three color channels: Red, Green, and Blue (RGB).\n",
    "\n",
    "The **2D Fourier Transform** converts spatial domain information (pixel values at different positions) into frequency domain information (how much each spatial frequency contributes to the image). \n",
    "\n",
    "**Key Concepts:**\n",
    "- **Low frequencies** correspond to slowly varying features (smooth regions, overall color)\n",
    "- **High frequencies** correspond to rapidly varying features (edges, fine details, noise)\n",
    "- The **2D real FFT** (`numpy.fft.rfft2`) is optimized for real-valued input (like image pixel values) and returns complex-valued frequency coefficients\n",
    "\n",
    "### Image Compression Principle\n",
    "\n",
    "By transforming an image to the frequency domain, we can:\n",
    "1. Identify which frequencies contain the most information\n",
    "2. Discard high-frequency components (fine details) to reduce data size\n",
    "3. Reconstruct an approximate image from the reduced frequency data\n",
    "\n",
    "This is the principle behind JPEG compression and many other image compression algorithms!\n",
    "\n",
    "### Helper Functions\n",
    "\n",
    "First, we'll provide helper functions to load and work with our sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d123f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "def display_image(img, title=\"Image\"):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(np.clip(img, 0, 1))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load sample images for testing\n",
    "sunset_img = load_image('sunset.npy')\n",
    "forest_img = load_image('forest.npy')\n",
    "ocean_img = load_image('ocean.npy')\n",
    "\n",
    "print(f\"Loaded images:\")\n",
    "print(f\"  Sunset: {sunset_img.shape}\")\n",
    "print(f\"  Forest: {forest_img.shape}\")\n",
    "print(f\"  Ocean: {ocean_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3509b06",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Display the sample images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(np.clip(sunset_img, 0, 1))\n",
    "axes[0].set_title('Sunset Scene')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(np.clip(forest_img, 0, 1))\n",
    "axes[1].set_title('Forest Scene')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(np.clip(ocean_img, 0, 1))\n",
    "axes[2].set_title('Ocean Scene')\n",
    "axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ae434",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Part A**: Computing the 2D Fourier Transform\n",
    "\n",
    "Now you'll implement a function that computes the 2D Fourier transform of a color image.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Write a function `image_to_fourier(img)` that:\n",
    "1. Takes a color image as a 3D numpy array with shape `(height, width, 3)`\n",
    "2. Computes the 2D real Fourier transform (`numpy.fft.rfft2`) separately for each color channel\n",
    "3. Returns a tuple of three arrays, one for each color channel's Fourier transform\n",
    "\n",
    "### Mathematical Background\n",
    "\n",
    "For a 2D array (like one color channel), the 2D Fourier transform is:\n",
    "\n",
    "$$F(k_x, k_y) = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} f(x,y) \\cdot e^{-2\\pi i (k_x x / N_x + k_y y / N_y)}$$\n",
    "\n",
    "where:\n",
    "- $f(x,y)$ is the pixel value at position $(x,y)$\n",
    "- $F(k_x, k_y)$ is the Fourier coefficient for spatial frequency $(k_x, k_y)$\n",
    "- $N_x, N_y$ are the image dimensions\n",
    "\n",
    "The function `numpy.fft.rfft2` efficiently computes this transform, exploiting the fact that our input is real-valued.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Input validation: check that `img` is a 3D array with shape `(height, width, 3)`\n",
    "- Use `numpy.fft.rfft2()` on each color channel separately\n",
    "- The red channel is `img[:, :, 0]`, green is `img[:, :, 1]`, blue is `img[:, :, 2]`\n",
    "- Return a tuple: `(fourier_red, fourier_green, fourier_blue)`\n",
    "- Each returned array will be complex-valued with shape `(height, width//2 + 1)` due to rfft2's optimization\n",
    "\n",
    "**Parameters:**\n",
    "- `img`: numpy array of shape `(height, width, 3)`, the input color image\n",
    "\n",
    "**Returns:**\n",
    "- `fourier_transforms`: tuple of 3 numpy arrays, each containing the 2D Fourier transform of one color channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaea6d3",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def image_to_fourier(img):\n",
    "    \n",
    "    return (fourier_red, fourier_green, fourier_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6c151",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b93720",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Part B**: Inverse Fourier Transform (Image Reconstruction)\n",
    "\n",
    "Now you'll implement the inverse operation: converting Fourier transforms back to an image.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Write a function `fourier_to_image(fourier_transforms, original_shape)` that:\n",
    "1. Takes a tuple of three Fourier transforms (one per color channel)\n",
    "2. Takes the original image shape `(height, width)`\n",
    "3. Applies the inverse 2D real FFT (`numpy.fft.irfft2`) to each channel\n",
    "4. Reconstructs and returns the color image as a 3D array\n",
    "\n",
    "### Mathematical Background\n",
    "\n",
    "The **inverse Fourier transform** converts frequency domain data back to spatial domain:\n",
    "\n",
    "$$f(x,y) = \\frac{1}{N_x N_y} \\sum_{k_x=0}^{N_x-1} \\sum_{k_y=0}^{N_y-1} F(k_x, k_y) \\cdot e^{2\\pi i (k_x x / N_x + k_y y / N_y)}$$\n",
    "\n",
    "The function `numpy.fft.irfft2` efficiently computes this inverse transform. When paired with `rfft2`, we should get back exactly the original image (up to numerical precision).\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Input `fourier_transforms` should be a tuple of 3 complex arrays (from Part A)\n",
    "- Input `original_shape` should be a tuple `(height, width)` specifying the original image dimensions\n",
    "- Apply `numpy.fft.irfft2(fourier_channel, s=original_shape)` to each Fourier transform\n",
    "  - The `s` parameter is crucial! It tells `irfft2` the original dimensions\n",
    "- Stack the three reconstructed channels into a 3D array with shape `(height, width, 3)`\n",
    "- Return the reconstructed image array\n",
    "\n",
    "**Note:** The reconstructed image should be virtually identical to the original (differences only due to floating-point precision).\n",
    "\n",
    "**Parameters:**\n",
    "- `fourier_transforms`: tuple of 3 numpy arrays, the Fourier transforms from Part A\n",
    "- `original_shape`: tuple `(height, width)`, the dimensions of the original image\n",
    "\n",
    "**Returns:**\n",
    "- `img_reconstructed`: numpy array of shape `(height, width, 3)`, the reconstructed color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eec44f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def fourier_to_image(fourier_transforms, original_shape):\n",
    "    \n",
    "    return img_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faca055",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c3c65",
   "metadata": {},
   "source": [
    "### Example: Round-Trip Transform and Reconstruction\n",
    "\n",
    "Let's demonstrate the full pipeline: transform an image to Fourier space and reconstruct it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb81869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an image to test\n",
    "test_image = sunset_img\n",
    "\n",
    "# Transform to Fourier space\n",
    "fourier_transforms = image_to_fourier(test_image)\n",
    "print(f\"Original image shape: {test_image.shape}\")\n",
    "print(f\"Fourier transform shapes: {[f.shape for f in fourier_transforms]}\")\n",
    "\n",
    "# Reconstruct from Fourier space\n",
    "reconstructed_image = fourier_to_image(fourier_transforms, test_image.shape[:2])\n",
    "print(f\"Reconstructed image shape: {reconstructed_image.shape}\")\n",
    "\n",
    "# Calculate reconstruction error\n",
    "error = np.max(np.abs(reconstructed_image - test_image))\n",
    "print(f\"\\nMaximum reconstruction error: {error:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bedc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original vs reconstructed\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(np.clip(test_image, 0, 1))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(np.clip(reconstructed_image, 0, 1))\n",
    "axes[1].set_title('Reconstructed Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The images should be visually identical!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa37044",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# **Question 2**: Frequency Filtering of 1D Time Series\n",
    "\n",
    "In this question, you'll implement a frequency filter for 1D time series data using Fourier transforms. Frequency filtering is a fundamental technique in signal processing that allows us to remove unwanted frequency components from signals, such as noise or interference.\n",
    "\n",
    "### Background: Frequency Domain Filtering\n",
    "\n",
    "A time series signal $x(t)$ can be decomposed into its frequency components using the **Fourier Transform**. In the frequency domain, we can:\n",
    "\n",
    "1. **Identify** which frequencies are present in the signal\n",
    "2. **Modify** the frequency content by zeroing out unwanted frequencies\n",
    "3. **Reconstruct** the filtered signal using the inverse Fourier transform\n",
    "\n",
    "This process is called **frequency filtering** or **spectral filtering**.\n",
    "\n",
    "### Types of Frequency Filters\n",
    "\n",
    "- **Low-pass filter**: Keeps frequencies below a cutoff frequency (removes high frequencies)\n",
    "- **High-pass filter**: Keeps frequencies above a cutoff frequency (removes low frequencies)  \n",
    "- **Band-pass filter**: Keeps frequencies within a specific range (removes frequencies outside the band)\n",
    "- **Band-stop filter**: Removes frequencies within a specific range (keeps frequencies outside the band)\n",
    "\n",
    "In this question, you'll implement a **band-pass filter** that keeps only frequencies between a minimum and maximum frequency.\n",
    "\n",
    "### Mathematical Background\n",
    "\n",
    "For a discrete signal $x[n]$ with $N$ samples, the process is:\n",
    "\n",
    "1. **Forward FFT**: $X[k] = \\text{FFT}(x[n])$ converts time domain to frequency domain\n",
    "2. **Filtering**: Set $X[k] = 0$ for frequencies outside the desired range\n",
    "3. **Inverse FFT**: $x_{\\text{filtered}}[n] = \\text{IFFT}(X[k])$ converts back to time domain\n",
    "\n",
    "The frequency corresponding to each FFT bin $k$ is:\n",
    "$$f[k] = \\frac{k \\cdot f_s}{N}$$\n",
    "\n",
    "where $f_s$ is the sampling frequency and $k$ ranges from $0$ to $N-1$.\n",
    "\n",
    "### Applications\n",
    "\n",
    "Frequency filtering is used in:\n",
    "- **Audio processing**: Removing noise, equalizing music\n",
    "- **Biomedical signals**: Filtering ECG, EEG data\n",
    "- **Communications**: Removing interference\n",
    "- **Image processing**: Smoothing, edge detection (2D filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252299d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Your Task\n",
    "\n",
    "Write a function `frequency_filter(signal, min_freq, max_freq, sample_rate=1.0)` that:\n",
    "1. Takes a 1D real-valued time series signal\n",
    "2. Applies a band-pass filter to keep only frequencies between `min_freq` and `max_freq`\n",
    "3. Returns the filtered signal in the time domain\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- **Input validation**: Check that `signal` is a 1D numpy array\n",
    "- **Forward FFT**: Use `numpy.fft.fft()` to transform the signal to frequency domain\n",
    "- **Frequency calculation**: Compute the frequency array using `numpy.fft.fftfreq()`\n",
    "- **Filtering**: \n",
    "  - Set FFT coefficients to zero for frequencies outside the range `[min_freq, max_freq]`\n",
    "  - Handle both positive and negative frequencies correctly (FFT output is complex and symmetric for real input)\n",
    "- **Inverse FFT**: Use `numpy.fft.ifft()` and take the real part to get the filtered signal\n",
    "- **Return**: The filtered signal as a real-valued numpy array\n",
    "\n",
    "### Mathematical Details\n",
    "\n",
    "For a signal with `N` samples and sampling rate `sample_rate`:\n",
    "- Frequency array: `freqs = np.fft.fftfreq(N, 1/sample_rate)`\n",
    "- Keep frequencies where: `min_freq <= |freq| <= max_freq`\n",
    "- Zero out all other frequency components\n",
    "- The DC component (frequency = 0) should be kept if `min_freq <= 0`\n",
    "\n",
    "**Parameters:**\n",
    "- `signal`: numpy array, 1D real-valued time series\n",
    "- `min_freq`: float, minimum frequency to keep (in Hz)\n",
    "- `max_freq`: float, maximum frequency to keep (in Hz)  \n",
    "- `sample_rate`: float, sampling rate in Hz (default: 1.0)\n",
    "\n",
    "**Returns:**\n",
    "- `filtered_signal`: numpy array, filtered time series signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699439f7",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def frequency_filter(signal, min_freq, max_freq, sample_rate=1.0):\n",
    "    \n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400632b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487f202",
   "metadata": {},
   "source": [
    "### Example 1: Filtering a Noisy Signal\n",
    "\n",
    "Let's create a signal with multiple frequency components and demonstrate how frequency filtering works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test signal with multiple frequency components\n",
    "np.random.seed(rng_seed)  # For reproducible noise\n",
    "\n",
    "# Time parameters\n",
    "duration = 2.0  # seconds\n",
    "sample_rate = 500  # Hz\n",
    "t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "\n",
    "# Create a composite signal\n",
    "signal_clean = (2.0 * np.sin(2 * np.pi * 5 * t) +    # 5 Hz component\n",
    "                1.5 * np.sin(2 * np.pi * 15 * t) +   # 15 Hz component\n",
    "                0.8 * np.sin(2 * np.pi * 50 * t))    # 50 Hz component\n",
    "\n",
    "# Add high-frequency noise\n",
    "noise = 0.5 * np.random.randn(len(t))\n",
    "signal_noisy = signal_clean + noise\n",
    "\n",
    "print(f\"Signal properties:\")\n",
    "print(f\"  Duration: {duration} seconds\")\n",
    "print(f\"  Sample rate: {sample_rate} Hz\")\n",
    "print(f\"  Number of samples: {len(t)}\")\n",
    "print(f\"  Clean signal contains: 5 Hz, 15 Hz, and 50 Hz components\")\n",
    "print(f\"  Added random noise with std = 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198096cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different frequency filters\n",
    "low_pass_filtered = frequency_filter(signal_noisy, 0, 20, sample_rate)      # Keep 0-20 Hz\n",
    "band_pass_filtered = frequency_filter(signal_noisy, 10, 25, sample_rate)    # Keep 10-25 Hz\n",
    "high_pass_filtered = frequency_filter(signal_noisy, 30, 250, sample_rate)   # Keep 30-250 Hz\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Time domain plots\n",
    "axes[0, 0].plot(t[:500], signal_noisy[:500], 'b-', alpha=0.7, label='Noisy signal')\n",
    "axes[0, 0].plot(t[:500], signal_clean[:500], 'r-', linewidth=2, label='Clean signal')\n",
    "axes[0, 0].set_title('Original Signals (first 1 second)')\n",
    "axes[0, 0].set_xlabel('Time (s)')\n",
    "axes[0, 0].set_ylabel('Amplitude')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(t[:500], low_pass_filtered[:500], 'g-', linewidth=1.5, label='Low-pass (0-20 Hz)')\n",
    "axes[0, 1].plot(t[:500], signal_clean[:500], 'r--', alpha=0.7, label='Original clean')\n",
    "axes[0, 1].set_title('Low-pass Filtered (removes noise)')\n",
    "axes[0, 1].set_xlabel('Time (s)')\n",
    "axes[0, 1].set_ylabel('Amplitude')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(t[:500], band_pass_filtered[:500], 'm-', linewidth=1.5, label='Band-pass (10-25 Hz)')\n",
    "axes[1, 0].set_title('Band-pass Filtered (keeps 15 Hz component)')\n",
    "axes[1, 0].set_xlabel('Time (s)')\n",
    "axes[1, 0].set_ylabel('Amplitude')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(t[:500], high_pass_filtered[:500], 'orange', linewidth=1.5, label='High-pass (30+ Hz)')\n",
    "axes[1, 1].set_title('High-pass Filtered (keeps 50 Hz + noise)')\n",
    "axes[1, 1].set_xlabel('Time (s)')\n",
    "axes[1, 1].set_ylabel('Amplitude')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e9574",
   "metadata": {},
   "source": [
    "### Example 2: Applications in Signal Processing\n",
    "\n",
    "Here's an example of how frequency filtering is used to clean up real-world signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simulating an ECG signal with power line interference\n",
    "duration = 3.0\n",
    "sample_rate = 250\n",
    "t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "\n",
    "# Simulated ECG-like signal (simplified)\n",
    "ecg_clean = (np.sin(2 * np.pi * 1.2 * t) * np.exp(-((t % 0.8) - 0.1)**2 / 0.01) + \n",
    "             0.3 * np.sin(2 * np.pi * 2 * t))\n",
    "\n",
    "# Add 60 Hz power line interference (common in electrical recordings)\n",
    "interference = 0.8 * np.sin(2 * np.pi * 60 * t)\n",
    "ecg_noisy = ecg_clean + interference\n",
    "\n",
    "# Apply filter to remove 60 Hz interference (notch filter effect)\n",
    "ecg_filtered = frequency_filter(ecg_noisy, 0, 50, sample_rate)  # Keep 0-50 Hz\n",
    "\n",
    "# Compare the signals\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "axes[0].plot(t, ecg_clean, 'g-', linewidth=2, label='Clean ECG')\n",
    "axes[0].set_title('Clean ECG Signal')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(t, ecg_noisy, 'r-', alpha=0.7, label='ECG + 60Hz interference')\n",
    "axes[1].set_title('ECG with 60 Hz Power Line Interference')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(t, ecg_filtered, 'b-', linewidth=1.5, label='Filtered ECG (0-50 Hz)')\n",
    "axes[2].plot(t, ecg_clean, 'g--', alpha=0.7, label='Original clean')\n",
    "axes[2].set_title('Filtered ECG (60 Hz interference removed)')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "axes[2].set_ylabel('Amplitude')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate signal quality improvement\n",
    "snr_before = 10 * np.log10(np.var(ecg_clean) / np.var(ecg_noisy - ecg_clean))\n",
    "snr_after = 10 * np.log10(np.var(ecg_clean) / np.var(ecg_filtered - ecg_clean))\n",
    "\n",
    "print(f\"Signal Quality Analysis:\")\n",
    "print(f\"  SNR before filtering: {snr_before:.1f} dB\")\n",
    "print(f\"  SNR after filtering:  {snr_after:.1f} dB\")\n",
    "print(f\"  Improvement: {snr_after - snr_before:.1f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df04c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b85b252",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Required disclosure of use of AI technology\n",
    "\n",
    "Please indicate whether you used AI to complete this homework. If you did, explain how you used it in the python cell below, as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce29cd",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# write ai disclosure here:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0808ece1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Upload the .zip file to Gradescope!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420c641",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bb473",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otter_grading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> result = image_to_fourier(sunset_img)\n>>> test_result = isinstance(result, tuple) and len(result) == 3\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> fr, fg, fb = image_to_fourier(forest_img)\n>>> test_result = np.iscomplexobj(fr) and np.iscomplexobj(fg) and np.iscomplexobj(fb)\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> fr, fg, fb = image_to_fourier(ocean_img)\n>>> h, w = (ocean_img.shape[0], ocean_img.shape[1])\n>>> expected_shape = (h, w // 2 + 1)\n>>> test_result = fr.shape == expected_shape and fg.shape == expected_shape and (fb.shape == expected_shape)\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fourier = image_to_fourier(sunset_img)\n>>> reconstructed = fourier_to_image(fourier, sunset_img.shape[:2])\n>>> test_result = isinstance(reconstructed, np.ndarray) and reconstructed.ndim == 3\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> fourier = image_to_fourier(forest_img)\n>>> reconstructed = fourier_to_image(fourier, forest_img.shape[:2])\n>>> test_result = reconstructed.shape == forest_img.shape\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> fourier = image_to_fourier(ocean_img)\n>>> reconstructed = fourier_to_image(fourier, ocean_img.shape[:2])\n>>> max_error = np.max(np.abs(reconstructed - ocean_img))\n>>> test_result = max_error < 1e-05\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_signal = np.sin(2 * np.pi * 0.5 * np.linspace(0, 1, 100))\n>>> filtered = frequency_filter(test_signal, 0.1, 1.0)\n>>> test_result = isinstance(filtered, np.ndarray) and len(filtered) == len(test_signal)\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> test_signal = np.random.randn(128)\n>>> filtered = frequency_filter(test_signal, 0.0, 0.5, sample_rate=1.0)\n>>> test_result = np.isrealobj(filtered)\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> t = np.linspace(0, 4, 1000)\n>>> sample_rate = 250\n>>> low_freq_signal = np.sin(2 * np.pi * 5 * t)\n>>> filtered = frequency_filter(low_freq_signal, 0, 10, sample_rate)\n>>> energy_original = np.sum(low_freq_signal ** 2)\n>>> energy_filtered = np.sum(filtered ** 2)\n>>> test_result = energy_filtered / energy_original > 0.9\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> t = np.linspace(0, 1, 1000)\n>>> sample_rate = 1000\n>>> high_freq_signal = np.sin(2 * np.pi * 100 * t)\n>>> filtered = frequency_filter(high_freq_signal, 0, 10, sample_rate)\n>>> energy_original = np.sum(high_freq_signal ** 2)\n>>> energy_filtered = np.sum(filtered ** 2)\n>>> test_result = energy_filtered / energy_original < 0.01\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
