{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8c4dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw9.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e79c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "#below line allows matplotlib plots to appear in cell output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14423dab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 1**: Power Method for Finding Maximum Eigenvalue\n",
    "\n",
    "The **power method** is an iterative algorithm for finding the largest eigenvalue (in absolute value) of a matrix. It's particularly useful for large sparse matrices where computing all eigenvalues would be computationally expensive.\n",
    "\n",
    "### Background: Eigenvalues and Eigenvectors\n",
    "\n",
    "For a square matrix $\\mathbf{A}$, an **eigenvector** $\\mathbf{v}$ and its corresponding **eigenvalue** $\\lambda$ satisfy:\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{v} = \\lambda \\mathbf{v}$$\n",
    "\n",
    "Every square matrix has eigenvalues $\\lambda_1, \\lambda_2, ..., \\lambda_n$ (some may be complex or repeated). We order them by absolute value: $|\\lambda_1| \\geq |\\lambda_2| \\geq ... \\geq |\\lambda_n|$.\n",
    "\n",
    "The **dominant eigenvalue** is $\\lambda_1$ (the one with largest absolute value).\n",
    "\n",
    "### The Power Method Algorithm\n",
    "\n",
    "The power method is based on a simple observation: if we repeatedly multiply a vector by matrix $\\mathbf{A}$, the result will increasingly point in the direction of the dominant eigenvector.\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "1. **Initialize**: Start with a random unit vector $\\mathbf{x}^{(0)}$ (where $||\\mathbf{x}^{(0)}|| = 1$)\n",
    "\n",
    "2. **Iterate** for $k = 1, 2, ..., N$:\n",
    "   - Multiply by $\\mathbf{A}$: $\\mathbf{y}^{(k)} = \\mathbf{A} \\mathbf{x}^{(k-1)}$\n",
    "   - Normalize: $\\mathbf{x}^{(k)} = \\frac{\\mathbf{y}^{(k)}}{||\\mathbf{y}^{(k)}||}$\n",
    "\n",
    "3. **Extract eigenvalue**: After $N$ iterations, $\\mathbf{x}^{(N)}$ approximates the dominant eigenvector. The corresponding eigenvalue can be computed using the **Rayleigh quotient**:\n",
    "\n",
    "$$\\lambda_1 \\approx \\frac{\\mathbf{x}^T \\mathbf{A} \\mathbf{x}}{\\mathbf{x}^T \\mathbf{x}} = \\mathbf{x}^T \\mathbf{A} \\mathbf{x}$$\n",
    "\n",
    "(The denominator equals 1 since $\\mathbf{x}$ is a unit vector)\n",
    "\n",
    "### Why Does This Work?\n",
    "\n",
    "Any vector $\\mathbf{x}^{(0)}$ can be written as a linear combination of eigenvectors:\n",
    "$$\\mathbf{x}^{(0)} = c_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2 + ... + c_n \\mathbf{v}_n$$\n",
    "\n",
    "After $k$ multiplications by $\\mathbf{A}$:\n",
    "$$\\mathbf{A}^k \\mathbf{x}^{(0)} = c_1 \\lambda_1^k \\mathbf{v}_1 + c_2 \\lambda_2^k \\mathbf{v}_2 + ... + c_n \\lambda_n^k \\mathbf{v}_n$$\n",
    "\n",
    "Since $|\\lambda_1| > |\\lambda_i|$ for $i > 1$, the term $\\lambda_1^k$ grows fastest, and the vector increasingly points toward $\\mathbf{v}_1$.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "Write a function `power_method(A, N)` that implements the power method to find the dominant eigenvalue of a square matrix.\n",
    "\n",
    "**Requirements:**\n",
    "- Input `A` is a square numpy array (any size $n \\times n$)\n",
    "- Input `N` is the number of iterations to perform\n",
    "- Initialize a random unit vector using `np.random.rand(n)` then normalize it\n",
    "- Perform $N$ iterations of:\n",
    "  - Multiply: $\\mathbf{y} = \\mathbf{A} \\mathbf{x}$\n",
    "  - Normalize: $\\mathbf{x} = \\mathbf{y} / ||\\mathbf{y}||$\n",
    "- After $N$ iterations, compute the eigenvalue using: $\\lambda = \\mathbf{x}^T \\mathbf{A} \\mathbf{x}$\n",
    "- Return the estimated dominant eigenvalue\n",
    "\n",
    "**Parameters:**\n",
    "- `A`: numpy array, square matrix of shape (n, n)\n",
    "- `N`: int, number of iterations to perform\n",
    "\n",
    "**Returns:**\n",
    "- `eigenvalue`: float, the estimated dominant eigenvalue\n",
    "\n",
    "**Hints:**\n",
    "- Use `np.random.rand(n)` to create a random vector\n",
    "- Use `np.linalg.norm(x)` to compute the norm $||x||$\n",
    "- Use `np.dot(x, y)` or `x @ y` for matrix-vector multiplication\n",
    "- The Rayleigh quotient is: `x.T @ A @ x` or `np.dot(x, np.dot(A, x))`\n",
    "- For a unit vector $\\mathbf{x}$, we have $\\mathbf{x}^T \\mathbf{A} \\mathbf{x} = \\mathbf{x} \\cdot (\\mathbf{A} \\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36958c",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def power_method(A, N):\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Initialize random unit vector\n",
    "    x = np.random.rand(n)\n",
    "    x = ...  # normalize\n",
    "    \n",
    "    # Power iteration\n",
    "    for i in range(N):\n",
    "        # Multiply by A\n",
    "        y = ...\n",
    "        \n",
    "        # Normalize\n",
    "        x = ...\n",
    "    \n",
    "    # Compute eigenvalue using Rayleigh quotient\n",
    "    eigenvalue = ...\n",
    "    \n",
    "    return eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf3278",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49337610",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 2**: Nearest Neighbor Algorithm in 2D\n",
    "\n",
    "The **nearest neighbor algorithm** is a fundamental method in machine learning and data analysis. Given a query point and a dataset, it finds the data point that is closest to the query point. This has applications in classification, clustering, anomaly detection, and more.\n",
    "\n",
    "### Background: Distance Metrics\n",
    "\n",
    "To find the nearest neighbor, we need to measure the distance between points. In 2D, the most common metric is the **Euclidean distance**:\n",
    "\n",
    "For two points $\\mathbf{p} = (p_x, p_y)$ and $\\mathbf{q} = (q_x, q_y)$, the Euclidean distance is:\n",
    "\n",
    "$$d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2}$$\n",
    "\n",
    "### Part a: Finding the Nearest Neighbor\n",
    "\n",
    "Write a function `find_nearest_neighbor(data, query_point)` that finds the nearest neighbor to a query point in a 2D dataset.\n",
    "\n",
    "**Algorithm:**\n",
    "1. For each point in the dataset, compute the Euclidean distance to the query point\n",
    "2. Find the index of the point with the minimum distance\n",
    "3. Return that index\n",
    "\n",
    "**Requirements:**\n",
    "- Input `data` is a numpy array of shape $(N, 2)$ where each row is a 2D point\n",
    "- Input `query_point` is a numpy array of shape $(2,)$ representing the query coordinates\n",
    "- Compute Euclidean distance: $d_i = \\sqrt{(x_i - q_x)^2 + (y_i - q_y)^2}$\n",
    "- Return the integer index $i$ of the nearest neighbor (the point with minimum distance)\n",
    "\n",
    "**Parameters:**\n",
    "- `data`: numpy array of shape (N, 2), dataset of 2D points\n",
    "- `query_point`: numpy array of shape (2,), the query point coordinates\n",
    "\n",
    "**Returns:**\n",
    "- `index`: int, the index of the nearest neighbor in the data array\n",
    "\n",
    "**Hints:**\n",
    "- Use `np.linalg.norm()` to compute Euclidean distance, or compute it manually\n",
    "- You can compute distances to all points at once using array operations\n",
    "- Use `np.argmin()` to find the index of the minimum distance\n",
    "- For vectorized distance computation: `distances = np.linalg.norm(data - query_point, axis=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36139f15",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def find_nearest_neighbor(data, query_point):\n",
    "    # Compute distances from query_point to all data points\n",
    "    distances = ...\n",
    "    \n",
    "    # Find the index of minimum distance\n",
    "    index = ...\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda531d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844dce9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part b: Visualizing Nearest Neighbor Regions\n",
    "\n",
    "Now we'll visualize the nearest neighbor algorithm by creating a **Voronoi diagram** - a partition of the plane into regions, where each region contains all points closest to a particular data point.\n",
    "\n",
    "**Concept:**\n",
    "- Create a dense grid of query points covering the data region\n",
    "- For each grid point, find its nearest neighbor from the dataset\n",
    "- Color each grid point according to which data point is its nearest neighbor\n",
    "- This creates colored regions showing the \"zones of influence\" for each data point\n",
    "\n",
    "Write a function `plot_nearest_neighbor_regions(data, show_plot=False)` that visualizes these regions.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Determine the bounds of the data (min and max x and y coordinates)\n",
    "2. Create a dense grid of points covering this region (e.g., 100Ã—100 grid)\n",
    "3. For each grid point, use `find_nearest_neighbor()` to determine which data point is closest\n",
    "4. Create a plot where grid points are colored by their nearest neighbor\n",
    "5. Overlay the original data points on top\n",
    "\n",
    "**Requirements:**\n",
    "- Input `data` is a numpy array of shape $(N, 2)$\n",
    "- Determine data bounds with some padding (e.g., extend 10% beyond min/max)\n",
    "- Create a meshgrid with at least 300 points in each direction\n",
    "- Use `find_nearest_neighbor()` from part (a) for each grid point\n",
    "- Plot the colored regions using `plt.scatter()` or `plt.contourf()`\n",
    "- Overlay the original data points with different markers\n",
    "- Include appropriate labels, title, and legend\n",
    "- Return the matplotlib figure object\n",
    "\n",
    "**Parameters:**\n",
    "- `data`: numpy array of shape (N, 2), dataset of 2D points\n",
    "- `show_plot`: bool, default False. If True, call `plt.show()`\n",
    "\n",
    "**Returns:**\n",
    "- `fig`: matplotlib figure object\n",
    "\n",
    "**Plotting Guidelines:**\n",
    "- Use a colormap (e.g., 'tab10', 'Set3', or 'rainbow') to distinguish regions\n",
    "- Plot grid points with small alpha (e.g., 0.3) to show regions as colored areas\n",
    "- Plot original data points with larger markers and black edges\n",
    "- Set appropriate axis labels: \"x\" and \"y\"\n",
    "- Title: \"Nearest Neighbor Regions (Voronoi Diagram)\"\n",
    "- Make sure the plot works for different data sizes (e.g., 3, 5, 10, or more points)\n",
    "\n",
    "**Hints:**\n",
    "- Use `np.meshgrid()` to create the grid\n",
    "- Flatten the grid to get all query points: `grid_points = np.c_[xx.ravel(), yy.ravel()]`\n",
    "- Use a loop or list comprehension to find nearest neighbors for all grid points\n",
    "- Reshape the results back to grid shape for plotting\n",
    "- For coloring regions, `plt.scatter()` with small `s` and `alpha` works well\n",
    "\n",
    "Note: This may not run instantly but should run within ~10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fd1b6",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_nearest_neighbor_regions(data, show_plot=False):\n",
    "    # Determine data bounds with padding\n",
    "    x_min, y_min = data.min(axis=0)\n",
    "    x_max, y_max = data.max(axis=0)\n",
    "    \n",
    "    # Add padding\n",
    "    ...\n",
    "    \n",
    "    # Create grid\n",
    "    n_grid = 100\n",
    "    xx, yy = np.meshgrid(...)\n",
    "    \n",
    "    # Flatten grid\n",
    "    grid_points = ...\n",
    "    \n",
    "    # Find nearest neighbor for each grid point\n",
    "    nearest_indices = ...\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Plot colored regions\n",
    "    ...\n",
    "    \n",
    "    # Plot original data points\n",
    "    ...\n",
    "    \n",
    "    # Add labels and formatting\n",
    "    ...\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282adb7d",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a random dataset with 10 points for plotting\n",
    "example_data = np.random.uniform(low = 0, high = 1, size = (10,2))\n",
    "\n",
    "# Plot the nearest neighbor regions\n",
    "fig = plot_nearest_neighbor_regions(example_data, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5549d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce4352",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## **Question 3**: Taylor Series Approximation\n",
    "\n",
    "A **Taylor series** is a powerful mathematical tool that approximates an analytic function using a polynomial. By including more terms, we can achieve increasingly accurate approximations near a chosen center point.\n",
    "\n",
    "### Background: Taylor Series\n",
    "\n",
    "For an analytic function $f(x)$, the Taylor series centered at $x_0$ is:\n",
    "\n",
    "$$f(x) \\approx \\sum_{n=0}^{N} \\frac{f^{(n)}(x_0)}{n!}(x - x_0)^n$$\n",
    "\n",
    "where $f^{(n)}(x_0)$ denotes the $n$-th derivative of $f$ evaluated at $x_0$.\n",
    "\n",
    "Expanding this sum:\n",
    "$$f(x) \\approx f(x_0) + f'(x_0)(x-x_0) + \\frac{f''(x_0)}{2!}(x-x_0)^2 + \\frac{f'''(x_0)}{3!}(x-x_0)^3 + ... + \\frac{f^{(N)}(x_0)}{N!}(x-x_0)^N$$\n",
    "\n",
    "The Taylor series is most accurate near $x_0$ and becomes less accurate as we move away from the center point.\n",
    "\n",
    "### The Function: $f(x) = e^x + \\sin(x)$\n",
    "\n",
    "For this question, we'll work with the function:\n",
    "$$f(x) = e^x + \\sin(x)$$\n",
    "\n",
    "This function is analytic everywhere, making it perfect for Taylor series approximation. The derivatives follow patterns:\n",
    "- For $e^x$: all derivatives are $e^x$\n",
    "- For $\\sin(x)$: derivatives cycle through $\\sin(x), \\cos(x), -\\sin(x), -\\cos(x), ...$\n",
    "\n",
    "### Part a: Computing the Taylor Series\n",
    "\n",
    "Write a function `taylor_approximation(N, x, x_0)` that computes the Taylor series approximation of $f(x) = e^x + \\sin(x)$ up to order $N$, centered at $x_0$, and evaluates it at point $x$.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Compute the derivatives of $f(x) = e^x + \\sin(x)$ up to order $N$ at point $x_0$\n",
    "2. For each term $n = 0, 1, 2, ..., N$:\n",
    "   - Compute $\\frac{f^{(n)}(x_0)}{n!}(x - x_0)^n$\n",
    "3. Sum all terms to get the approximation\n",
    "\n",
    "**Requirements:**\n",
    "- Input `N` is the highest order term to include (integer $\\geq 0$)\n",
    "- Input `x` is the point at which to evaluate the approximation (float)\n",
    "- Input `x_0` is the center point of the Taylor series (float)\n",
    "- Compute derivatives analytically:\n",
    "  - $\\frac{d^n}{dx^n}(e^x) = e^x$ for all $n$\n",
    "  - $\\frac{d^n}{dx^n}(\\sin(x))$ cycles: $\\sin(x), \\cos(x), -\\sin(x), -\\cos(x), ...$\n",
    "- Return the sum of all terms from $n=0$ to $n=N$\n",
    "\n",
    "**Parameters:**\n",
    "- `N`: int, highest order term (e.g., N=3 means include terms up to $(x-x_0)^3$)\n",
    "- `x`: float, point at which to evaluate the approximation\n",
    "- `x_0`: float, center point of the Taylor series\n",
    "\n",
    "**Returns:**\n",
    "- `approximation`: float, the Taylor series approximation $f(x) \\approx \\sum_{n=0}^{N} \\frac{f^{(n)}(x_0)}{n!}(x - x_0)^n$\n",
    "\n",
    "**Hints:**\n",
    "- Use `np.exp()` for exponential and `np.sin()`, `np.cos()` for trigonometric functions\n",
    "- Use `np.math.factorial(n)` or `scipy.special.factorial(n)` for $n!$\n",
    "- For sin derivatives: use `n % 4` to determine which function (0: sin, 1: cos, 2: -sin, 3: -cos)\n",
    "- Remember that $0! = 1$ and $(x-x_0)^0 = 1$\n",
    "- Build the sum term by term in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa1958",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def taylor_approximation(N, x, x_0):\n",
    "    \n",
    "    return approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682bda2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55894570",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part b: Visualizing Taylor Series Convergence\n",
    "\n",
    "Now we'll visualize how Taylor series approximations improve as we include more terms. This will help us understand how the approximation becomes more accurate near the center point.\n",
    "\n",
    "**Concept:**\n",
    "- Plot the true function $f(x) = e^x + \\sin(x)$ over a range centered at $x_0$\n",
    "- Overlay Taylor series approximations of increasing order: $0, 1, 2, ..., N$\n",
    "- Each approximation should be plotted as a different line\n",
    "- This shows how adding more terms makes the approximation converge to the true function\n",
    "\n",
    "Write a function `plot_taylor_series(N, x_0, show_plot=False)` that creates this visualization.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Define a range of x values centered at $x_0$ (e.g., from $x_0 - 5$ to $x_0 + 5$)\n",
    "2. Compute the true function values: $f(x) = e^x + \\sin(x)$ for all x in the range\n",
    "3. For each order $n = 0, 1, 2, ..., N$:\n",
    "   - Compute the Taylor approximation at each x value using `taylor_approximation(n, x, x_0)`\n",
    "   - Plot these values\n",
    "4. Create a legend showing which line corresponds to which order\n",
    "5. Return the figure object\n",
    "\n",
    "**Requirements:**\n",
    "- Input `N` is the maximum order to plot (integer $\\geq 0$)\n",
    "- Input `x_0` is the center point of the Taylor series (float)\n",
    "- Create a range of at least 200 x values from $x_0 - 5$ to $x_0 + 5$\n",
    "- Plot the true function as a thick black line with label \"True function\"\n",
    "- Plot each Taylor approximation (orders 0 through N) with different colors\n",
    "- Label each approximation as \"Order 0\", \"Order 1\", ..., \"Order N\"\n",
    "- Include axis labels: \"x\" and \"f(x)\"\n",
    "- Include title: \"Taylor Series Approximation of $e^x + \\sin(x)$ centered at $x_0 = $ {x_0:.1f}\"\n",
    "- Include a legend\n",
    "- Include a vertical dashed line at $x_0$ to show the center point\n",
    "- Return the matplotlib figure object\n",
    "\n",
    "**Parameters:**\n",
    "- `N`: int, maximum order of Taylor series to plot\n",
    "- `x_0`: float, center point of the Taylor series\n",
    "- `show_plot`: bool, default False. If True, call `plt.show()`\n",
    "\n",
    "**Returns:**\n",
    "- `fig`: matplotlib figure object containing the plot\n",
    "\n",
    "**Hints:**\n",
    "- Use `np.linspace(...)` to create the x range\n",
    "- Use a loop to plot each order's approximation\n",
    "- You can use a list comprehension to compute approximations: `[taylor_approximation(n, xi, x_0) for xi in x_range]`\n",
    "- Use `plt.axvline(x_0, linestyle='--', color='gray', alpha=0.5)` to add the vertical line at center\n",
    "- Use different line styles or colors for different orders (matplotlib will auto-cycle colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493b3dd",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_taylor_series(N, x_0, show_plot=False):\n",
    "\n",
    "    ...\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ...\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5deb3a",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot Taylor series centered at x_0 = 0\n",
    "fig = plot_taylor_series(N=5, x_0=0, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d34fa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d410f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Required disclosure of use of AI technology\n",
    "\n",
    "Please indicate whether you used AI to complete this homework. If you did, explain how you used it in the python cell below, as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0649092",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# write ai disclosure here:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2437a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Upload the .zip file to Gradescope!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db096ea7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326722e3",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otter_grading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> A_test = np.array([[2, 1], [1, 2]])\n>>> result = power_method(A_test, 20)\n>>> test_result = isinstance(result, (int, float, np.floating))\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> A = np.array([[3, 1], [1, 3]])\n>>> estimated = power_method(A, 50)\n>>> true_max = np.max(np.abs(np.linalg.eigvals(A)))\n>>> test_result = abs(estimated - true_max) < 0.01\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> A = np.array([[4, 1, 0], [1, 4, 1], [0, 1, 4]])\n>>> estimated = power_method(A, 50)\n>>> true_max = np.max(np.abs(np.linalg.eigvals(A)))\n>>> test_result = abs(estimated - true_max) < 0.01\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.random.seed(rng_seed)\n>>> A = np.diag([5, 3, 1])\n>>> estimated = power_method(A, 30)\n>>> true_max = 5.0\n>>> test_result = abs(estimated - true_max) < 0.01\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> data_test = np.array([[0, 0], [1, 1], [2, 2]])\n>>> query_test = np.array([0.5, 0.5])\n>>> result = find_nearest_neighbor(data_test, query_test)\n>>> test_result = isinstance(result, (int, np.integer))\n>>> test_result\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> data = np.array([[0, 0], [1, 1], [2, 2]])\n>>> query = np.array([0.1, 0.1])\n>>> result = find_nearest_neighbor(data, query)\n>>> test_result = result == 0\n>>> bool(test_result)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_data_q2b = np.array([[0, 0], [1, 1], [2, 0]])\n>>> fig_test = plot_nearest_neighbor_regions(test_data_q2b, show_plot=False)\n>>> is_figure = isinstance(fig_test, plt.Figure)\n>>> plt.close(fig_test)\n>>> is_figure\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> test_data_small = np.array([[0, 0], [3, 3], [0, 3]])\n>>> fig_small = plot_nearest_neighbor_regions(test_data_small, show_plot=False)\n>>> has_figure = fig_small is not None\n>>> has_axes = len(fig_small.axes) > 0\n>>> plt.close(fig_small)\n>>> (has_figure, has_axes)\n(True, True)",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> result = taylor_approximation(3, 1.0, 0.0)\n>>> isinstance(result, (int, float, np.floating))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> x_0_test = 0.0\n>>> expected = np.exp(x_0_test) + np.sin(x_0_test)\n>>> result = taylor_approximation(0, x_0_test, x_0_test)\n>>> bool(abs(result - expected) < 1e-10)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> x_test = 0.5\n>>> x_0_test = 0.0\n>>> true_value = np.exp(x_test) + np.sin(x_test)\n>>> approx = taylor_approximation(10, x_test, x_0_test)\n>>> bool(abs(approx - true_value) < 1e-06)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fig_test = plot_taylor_series(3, 0.0, show_plot=False)\n>>> is_figure = isinstance(fig_test, plt.Figure)\n>>> plt.close(fig_test)\n>>> is_figure\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> N_test = 2\n>>> fig_test = plot_taylor_series(N_test, 0.0, show_plot=False)\n>>> ax = fig_test.axes[0]\n>>> num_lines = len(ax.get_lines())\n>>> has_correct_lines = num_lines >= N_test + 2\n>>> plt.close(fig_test)\n>>> has_correct_lines\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
